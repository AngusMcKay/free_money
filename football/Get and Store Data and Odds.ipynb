{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and Store Data and Odds\n",
    "Continuous loop getting SL data, doing predictions and getting Betfair odds for testing algorithm against odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook\n",
    "import datetime\n",
    "import time\n",
    "import importlib\n",
    "import config\n",
    "importlib.reload(config)\n",
    "from config import username, password, application, dbpw\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pymysql\n",
    "import sqlalchemy\n",
    "\n",
    "import xgboost as xgb\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from Levenshtein import distance as levenshtein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_url = 'https://www.sportinglife.com/football/fixtures-results/live'\n",
    "prediction_times = [50, 60, 70, 75, 80, 85]\n",
    "max_minutes_to_prediction_time = 0\n",
    "max_minutes_after_prediction_time = 1\n",
    "\n",
    "header = {'X-Application': application, 'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "auth = 'username='+username+'&password='+password\n",
    "bet_url = \"https://api.betfair.com/exchange/betting/json-rpc/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/angus/projects/betting/football/models/late_goals_test_models_2.pickle', 'rb') as f:\n",
    "    models_dicts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_and_goals(matches, prediction_times):\n",
    "    \n",
    "    matches_data = []\n",
    "    goals_data = []\n",
    "\n",
    "\n",
    "    for m in matches:\n",
    "        match_ref = m.get('match_reference', {}).get('id')\n",
    "        match_date = m.get('match_date')\n",
    "        match_time = m.get('match_time')\n",
    "\n",
    "        matches_data.append(\n",
    "            [\n",
    "                match_ref, match_date, match_time,\n",
    "                m.get('state'),\n",
    "                m.get('match_type'), \n",
    "                m.get('competition', {}).get('competition_reference', {}).get('id'),\n",
    "                m.get('competition', {}).get('name'),\n",
    "                str(m.get('round')),\n",
    "                m.get('legs'),\n",
    "                m.get('leg'),\n",
    "                m.get('team_score_a', {}).get('team', {}).get('team_reference', {}).get('id'),\n",
    "                m.get('team_score_a', {}).get('team', {}).get('name'),\n",
    "                m.get('team_score_a', {}).get('team', {}).get('short_name'),\n",
    "                m.get('team_score_a', {}).get('score', [])[0].get('score'),\n",
    "                m.get('team_score_b', {}).get('team', {}).get('team_reference', {}).get('id'),\n",
    "                m.get('team_score_b', {}).get('team', {}).get('name'),\n",
    "                m.get('team_score_b', {}).get('team', {}).get('short_name'),\n",
    "                m.get('team_score_b', {}).get('score', [])[0].get('score'),\n",
    "                m.get('match_outcome', {}).get('outcome'),\n",
    "                m.get('match_outcome', {}).get('result_type'),\n",
    "                m.get('match_outcome', {}).get('winner', {}).get('team_reference', {}).get('id'),\n",
    "                m.get('match_outcome', {}).get('winner', {}).get('name'),\n",
    "                m.get('match_outcome', {}).get('winner', {}).get('short_name'),\n",
    "                m.get('half_time_score', {}).get('home'),\n",
    "                m.get('half_time_score', {}).get('away'),\n",
    "                m.get('full_time_score', {}).get('home'),\n",
    "                m.get('full_time_score', {}).get('away'),\n",
    "                m.get('clock')\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        homegoals = m.get('homeGoals', [])\n",
    "        for g in homegoals:\n",
    "            player = g.get('team_player')\n",
    "            goal_id = g.get('id')\n",
    "            for goal in g.get('goal', []):\n",
    "                goals_data.append(\n",
    "                    [\n",
    "                        match_ref, match_date, match_time,\n",
    "                        player, goal_id,\n",
    "                        goal.get('type'),\n",
    "                        goal.get('time'),\n",
    "                        goal.get('event_id'),\n",
    "                        goal.get('event_time'),\n",
    "                        'home'\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        awaygoals = m.get('awayGoals', [])\n",
    "        for g in awaygoals:\n",
    "            player = g.get('team_player')\n",
    "            goal_id = g.get('id')\n",
    "            for goal in g.get('goal', []):\n",
    "                goals_data.append(\n",
    "                    [\n",
    "                        match_ref, match_date, match_time,\n",
    "                        player, goal_id,\n",
    "                        goal.get('type'),\n",
    "                        goal.get('time'),\n",
    "                        goal.get('event_id'),\n",
    "                        goal.get('event_time'),\n",
    "                        'away'\n",
    "                    ]\n",
    "                )\n",
    "    \n",
    "    matches_cols = [\n",
    "        'match_ref', 'match_date', 'match_time', 'state', 'match_type', 'competition_id', 'competition_name', \n",
    "        'round', 'legs', 'leg', 'team_a_id', 'team_a_name', 'team_a_short_name', 'team_a_score',\n",
    "        'team_b_id', 'team_b_name', 'team_b_short_name', 'team_b_score',\n",
    "        'outcome', 'result_type', 'winner_id', 'winner_name', 'winner_short_name',\n",
    "        'half_time_score_home', 'half_time_score_away',\n",
    "        'full_time_score_home', 'full_time_score_away', 'clock'\n",
    "    ]\n",
    "    matches_df = pd.DataFrame(matches_data, columns=matches_cols)\n",
    "    \n",
    "    goals_cols = [\n",
    "        'match_ref', 'match_date', 'match_time', 'player', 'goal_id', 'type', 'time', 'event_id', 'event_time', 'side'\n",
    "    ]\n",
    "    goals_df = pd.DataFrame(goals_data, columns=goals_cols)\n",
    "    \n",
    "    def get_extra_time(t):\n",
    "        time_split = t.replace(\"'\", \"\").split(\"+\")\n",
    "        if len(time_split)>1:\n",
    "            return int(time_split[1])\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    goals_df['time_regular'] = goals_df['time'].apply(lambda x: int(x.replace(\"'\", \"\").split(\"+\")[0]))\n",
    "    goals_df['time_extra'] = goals_df['time'].apply(get_extra_time)\n",
    "    \n",
    "    def get_minutes(c):\n",
    "        try:\n",
    "            if c == 'HT':\n",
    "                return 45\n",
    "            elif c == 'FT':\n",
    "                return 90\n",
    "            else:\n",
    "                return int(c.replace(\"'\", \"\").split(\"+\")[0])\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    matches_df['minutes_of_play'] = matches_df['clock'].apply(get_minutes)\n",
    "    \n",
    "    # add prediction times\n",
    "    matches_df['next_prediction_time'] = None\n",
    "    matches_df['minutes_to_next_prediction_time'] = None\n",
    "    matches_df['following_prediction_time'] = None\n",
    "    matches_df['minutes_to_following_prediction_time'] = None\n",
    "    reversed_prediction_times = prediction_times[::-1]\n",
    "    for idx, row in matches_df.iterrows():\n",
    "        for i, t in enumerate(reversed_prediction_times):\n",
    "            if row['minutes_of_play'] <= t + max_minutes_after_prediction_time:\n",
    "                matches_df.at[idx, 'next_prediction_time'] = t\n",
    "                matches_df.at[idx, 'minutes_to_next_prediction_time'] = t - row['minutes_of_play']\n",
    "                if t < max(reversed_prediction_times):\n",
    "                    matches_df.at[idx, 'following_prediction_time'] = reversed_prediction_times[i-1]\n",
    "                    matches_df.at[idx, 'minutes_to_following_prediction_time'] = reversed_prediction_times[i-1] - row['minutes_of_play']\n",
    "    \n",
    "    return matches_df, goals_df\n",
    "\n",
    "    \n",
    "def add_betting_details_to_data(viable_matches_with_betfair_id):\n",
    "    # A lot of these columns are placeholders to be populated later\n",
    "    viable_matches_with_betfair_id['total_goals'] = (viable_matches_with_betfair_id['team_a_score'] + viable_matches_with_betfair_id['team_b_score']).astype(int)\n",
    "    viable_matches_with_betfair_id['market'] = 'Over/Under ' + viable_matches_with_betfair_id['total_goals'].astype(str) + '.5 Goals'\n",
    "    viable_matches_with_betfair_id['market_type'] = 'OVER_UNDER_' + viable_matches_with_betfair_id['total_goals'].astype(str) + '5'\n",
    "    viable_matches_with_betfair_id['market_id'] = None\n",
    "\n",
    "    viable_matches_with_betfair_id['runner_name_over'] = 'Over ' + viable_matches_with_betfair_id['total_goals'].astype(str) + '.5 Goals'\n",
    "    viable_matches_with_betfair_id['selection_id_over'] = None\n",
    "    viable_matches_with_betfair_id['actual_odds_over_back_1'] = None\n",
    "    viable_matches_with_betfair_id['size_over_back_1'] = None\n",
    "    viable_matches_with_betfair_id['actual_odds_over_back_2'] = None\n",
    "    viable_matches_with_betfair_id['size_over_back_2'] = None\n",
    "    viable_matches_with_betfair_id['actual_odds_over_back_3'] = None\n",
    "    viable_matches_with_betfair_id['size_over_back_3'] = None\n",
    "    \n",
    "    viable_matches_with_betfair_id['actual_odds_over_lay_1'] = None\n",
    "    viable_matches_with_betfair_id['size_over_lay_1'] = None\n",
    "    viable_matches_with_betfair_id['actual_odds_over_lay_2'] = None\n",
    "    viable_matches_with_betfair_id['size_over_lay_2'] = None\n",
    "    viable_matches_with_betfair_id['actual_odds_over_lay_3'] = None\n",
    "    viable_matches_with_betfair_id['size_over_lay_3'] = None\n",
    "    \n",
    "    viable_matches_with_betfair_id['runner_name_under'] = 'Under ' + viable_matches_with_betfair_id['total_goals'].astype(str) + '.5 Goals'\n",
    "    viable_matches_with_betfair_id['selection_id_under'] = None\n",
    "    viable_matches_with_betfair_id['actual_odds_under_back_1'] = None\n",
    "    viable_matches_with_betfair_id['size_under_back_1'] = None\n",
    "    viable_matches_with_betfair_id['actual_odds_under_back_2'] = None\n",
    "    viable_matches_with_betfair_id['size_under_back_2'] = None\n",
    "    viable_matches_with_betfair_id['actual_odds_under_back_3'] = None\n",
    "    viable_matches_with_betfair_id['size_under_back_3'] = None\n",
    "    \n",
    "    viable_matches_with_betfair_id['actual_odds_under_lay_1'] = None\n",
    "    viable_matches_with_betfair_id['size_under_lay_1'] = None\n",
    "    viable_matches_with_betfair_id['actual_odds_under_lay_2'] = None\n",
    "    viable_matches_with_betfair_id['size_under_lay_2'] = None\n",
    "    viable_matches_with_betfair_id['actual_odds_under_lay_3'] = None\n",
    "    viable_matches_with_betfair_id['size_under_lay_3'] = None\n",
    "    \n",
    "    viable_matches_with_betfair_id['is_delayed'] = None\n",
    "    viable_matches_with_betfair_id['delay_time'] = None\n",
    "    viable_matches_with_betfair_id['total_matched'] = None\n",
    "    viable_matches_with_betfair_id['total_available'] = None\n",
    "    \n",
    "    return viable_matches_with_betfair_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_order_result(order_result):\n",
    "    instruction_report = order_result.get('instructionReports', [{}])[0]\n",
    "    instruction = instruction_report.get('instruction', {})\n",
    "    limit_order = instruction.get('limitOrder', {})\n",
    "    \n",
    "    return [\n",
    "        order_result.get('status', None),\n",
    "        order_result.get('marketId', None),\n",
    "        instruction.get('selectionId', None),\n",
    "        instruction.get('handicap', None),\n",
    "        limit_order.get('size', None),\n",
    "        limit_order.get('price', None),\n",
    "        limit_order.get('timeInForce', None),\n",
    "        limit_order.get('minFillSize', None),\n",
    "        instruction.get('orderType', None),\n",
    "        instruction.get('side', None),\n",
    "        instruction_report.get('errorCode', None),\n",
    "        instruction_report.get('betId', None),\n",
    "        instruction_report.get('placedDate', None),\n",
    "        instruction_report.get('averagePriceMatched', None),\n",
    "        instruction_report.get('sizeMatched', None),\n",
    "        instruction_report.get('orderStatus', None)\n",
    "    ]\n",
    "    \n",
    "order_cols = ['status', 'market_id', 'selection_id', 'handicap', 'size', 'price', 'time_in_force', 'min_fill_size',\n",
    "              'order_type', 'side', 'error_code', 'bet_id', 'placed_date', 'average_price_matched', 'size_matched', 'order_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_price(p):\n",
    "    # Price requirements    \n",
    "    # 1.01 → 2\t0.01\n",
    "    # 2→ 3\t0.02\n",
    "    # 3 → 4\t0.05\n",
    "    # 4 → 6\t0.1\n",
    "    # 6 → 10\t0.2\n",
    "    # 10 → 20\t0.5\n",
    "    # 20 → 30\t1\n",
    "    # 30 → 50\t2\n",
    "    # 50 → 100\t5\n",
    "    # 100 → 1000\t10\n",
    "    \n",
    "    if p <= 2:\n",
    "        r = 0.01\n",
    "        d = 2\n",
    "        p = round(np.ceil(p/r)*r, d)\n",
    "\n",
    "    elif p <= 3:\n",
    "        r = 0.02\n",
    "        d = 2\n",
    "        p = round(np.ceil(p/r)*r, d)\n",
    "        \n",
    "    elif p <= 4:\n",
    "        r = 0.05\n",
    "        d = 2\n",
    "        p = round(np.ceil(p/r)*r, d)\n",
    "    \n",
    "    elif p <= 6:\n",
    "        r = 0.1\n",
    "        d = 1\n",
    "        p = round(np.ceil(p/r)*r, d)\n",
    "        \n",
    "    elif p <= 10:\n",
    "        r = 0.2\n",
    "        d = 1\n",
    "        p = round(np.ceil(p/r)*r, d)\n",
    "        \n",
    "    elif p <= 20:\n",
    "        r = 0.5\n",
    "        d = 1\n",
    "        p = round(np.ceil(p/r)*r, d)\n",
    "        \n",
    "    elif p <= 30:\n",
    "        r = 1\n",
    "        d = 0\n",
    "        p = round(np.ceil(p/r)*r, d)\n",
    "        \n",
    "    elif p <= 50:\n",
    "        r = 2\n",
    "        d = 0\n",
    "        p = round(np.ceil(p/r)*r, d)\n",
    "        \n",
    "    elif p <= 100:\n",
    "        r = 5\n",
    "        d = 0\n",
    "        p = round(np.ceil(p/r)*r, d)\n",
    "        \n",
    "    elif p <= 1000:\n",
    "        r = 10\n",
    "        d = 0\n",
    "        p = round(np.ceil(p/r)*r, d)\n",
    "        \n",
    "    else:\n",
    "        return 999999\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting process\n",
      "\n",
      "Logged in!\n",
      "No predictions due, sleeping for 50 minutes\n"
     ]
    }
   ],
   "source": [
    "retry_counter = 0\n",
    "while True:\n",
    "    print('\\n\\nStarting process')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    # Betfair login\n",
    "    try:\n",
    "        login = requests.post('https://identitysso-cert.betfair.com/api/certlogin',\n",
    "                              cert=('/etc/ssl/client-2048.crt', '/etc/ssl/client-2048.key'),\n",
    "                              headers=header, data=auth, timeout=30)\n",
    "\n",
    "        if login.status_code==503: # Betfair site down code - they don't give expected time so just got to keep trying\n",
    "            logging.error('Login error '+str(login.status_code))\n",
    "            print('\\nLogin error, trying again in 1 minute')\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            login_success = login.json()['loginStatus']\n",
    "            if login_success=='TEMPORARY_BAN_TOO_MANY_REQUESTS':\n",
    "                print(f'Login response is TEMPORARY_BAN_TOO_MANY_REQUESTS so continue with existing ssoid')\n",
    "            elif login_success!='SUCCESS':\n",
    "                print(f'Login unsuccessful due to LoginStatus: {login_success}, try to continue with existing login')\n",
    "            else:\n",
    "                logging.info('Login '+str(login_success))\n",
    "                ssoid = login.json()['sessionToken']\n",
    "                print('\\nLogged in!')\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Login error: '+str(error))\n",
    "        \n",
    "        if retry_counter < 25:\n",
    "            print('\\nLogin error, trying again in 1 minute - retry counter at '+str(retry_counter))\n",
    "            retry_counter += 1\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "        else:\n",
    "            print('\\nLogin error, attempting to restart network manager and then try again in 1 minute')\n",
    "            os.system('echo '+supw+' | sudo -S service network-manager restart')\n",
    "            retry_counter = 0\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "    headers = {'X-Application': application, 'X-Authentication': ssoid, 'content-type': 'application/json'}\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Sporting Life live matches\n",
    "        livejson = urllib.request.urlopen(sl_url).read()\n",
    "        soup = BeautifulSoup(livejson)\n",
    "        soup_find = soup.body.find(attrs={\"type\": \"application/json\"})\n",
    "        soup_json = json.loads(soup_find.text)\n",
    "        matches = soup_json.get('props', {}).get('pageProps', {}).get('matches', [])\n",
    "\n",
    "\n",
    "        # If no live matches then sleep for 60 mins\n",
    "        if len(matches) == 0:\n",
    "            print(f'No live matches sleeping for 60 minutes')\n",
    "            time.sleep(60*60)\n",
    "            continue\n",
    "\n",
    "        matches_df, goals_df = get_matches_and_goals(matches, prediction_times)\n",
    "\n",
    "\n",
    "        # Check when next predictions due and sleep until next due time if none due immediately\n",
    "        matches_at_prediction_times = matches_df[matches_df['minutes_to_next_prediction_time'] <= max_minutes_to_prediction_time]\n",
    "        matches_pre_prediction_times = matches_df[matches_df['minutes_to_next_prediction_time'] > max_minutes_to_prediction_time]\n",
    "        \n",
    "        if len(matches_at_prediction_times) == 0 and len(matches_pre_prediction_times) == 0:\n",
    "            sleep_minutes = 60\n",
    "            print(f'No predictions due, sleeping for {sleep_minutes} minutes')\n",
    "            time.sleep(sleep_minutes*60)\n",
    "            continue\n",
    "                \n",
    "        elif len(matches_at_prediction_times) == 0:\n",
    "            sleep_minutes = min(matches_pre_prediction_times['minutes_to_next_prediction_time']) - max_minutes_to_prediction_time\n",
    "            print(f'No predictions due, sleeping for {sleep_minutes} minutes')\n",
    "            time.sleep(sleep_minutes*60)\n",
    "            continue\n",
    "        \n",
    "        elif len(matches_pre_prediction_times) == 0:\n",
    "            matches_at_prediction_times_with_following = matches_at_prediction_times[matches_at_prediction_times['minutes_to_following_prediction_time'].notnull()]\n",
    "            if len(matches_at_prediction_times_with_following) == 0:\n",
    "                sleep_minutes = 60\n",
    "            else:\n",
    "                sleep_minutes = min(matches_at_prediction_times_with_following['minutes_to_following_prediction_time']) - max_minutes_to_prediction_time\n",
    "                \n",
    "        else:\n",
    "            matches_at_prediction_times_with_following = matches_at_prediction_times[matches_at_prediction_times['minutes_to_following_prediction_time'].notnull()]\n",
    "            if len(matches_at_prediction_times_with_following) == 0:\n",
    "                sleep_minutes = min(matches_pre_prediction_times['minutes_to_next_prediction_time']) - max_minutes_to_prediction_time\n",
    "            else:\n",
    "                pre_sleep_time = min(matches_pre_prediction_times['minutes_to_next_prediction_time']) - max_minutes_to_prediction_time\n",
    "                at_sleep_time = min(matches_at_prediction_times_with_following['minutes_to_following_prediction_time']) - max_minutes_to_prediction_time\n",
    "                sleep_minutes = min(pre_sleep_time, at_sleep_time)\n",
    "\n",
    "\n",
    "        # Build model data\n",
    "        time_cutoffs = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90]\n",
    "        cap_at = 90\n",
    "        time_features = []\n",
    "        for i, t in enumerate(time_cutoffs):\n",
    "            goals_df[f'goals_pre_{t}m'] = ((goals_df[f'time_regular']<t) & (goals_df[f'time_regular']<=cap_at))*1\n",
    "            time_features += [f'goals_pre_{t}m']\n",
    "            if t > min(time_cutoffs):\n",
    "                goals_df[f'goals_{time_cutoffs[i-1]}m_to_{t}m'] = (\n",
    "                    goals_df[f'goals_pre_{t}m'] - goals_df[f'goals_pre_{time_cutoffs[i-1]}m'])\n",
    "                time_features += [f'goals_{time_cutoffs[i-1]}m_to_{t}m']\n",
    "\n",
    "            goals_df[f'goals_post_{t}m'] = ((goals_df[f'time_regular']>=t) & (goals_df[f'time_regular']<=cap_at))*1\n",
    "            time_features += [f'goals_post_{t}m']\n",
    "\n",
    "        # same for home and away goals\n",
    "        time_features_home_away = []\n",
    "        for i, t in enumerate(time_cutoffs):\n",
    "            goals_df[f'home_goals_pre_{t}m'] = ((goals_df[f'time_regular']<t) & (goals_df[f'time_regular']<=cap_at) & (goals_df[f'side']=='home'))*1\n",
    "            time_features_home_away += [f'home_goals_pre_{t}m']\n",
    "\n",
    "            goals_df[f'away_goals_pre_{t}m'] = ((goals_df[f'time_regular']<t) & (goals_df[f'time_regular']<=cap_at) & (goals_df[f'side']=='away'))*1\n",
    "            time_features_home_away += [f'away_goals_pre_{t}m']\n",
    "\n",
    "            if t > min(time_cutoffs):\n",
    "                goals_df[f'home_goals_{time_cutoffs[i-1]}m_to_{t}m'] = (\n",
    "                    goals_df[f'home_goals_pre_{t}m'] - goals_df[f'home_goals_pre_{time_cutoffs[i-1]}m'])\n",
    "                time_features_home_away += [f'home_goals_{time_cutoffs[i-1]}m_to_{t}m']\n",
    "\n",
    "                goals_df[f'away_goals_{time_cutoffs[i-1]}m_to_{t}m'] = (\n",
    "                    goals_df[f'away_goals_pre_{t}m'] - goals_df[f'away_goals_pre_{time_cutoffs[i-1]}m'])\n",
    "                time_features_home_away += [f'away_goals_{time_cutoffs[i-1]}m_to_{t}m']\n",
    "\n",
    "            goals_df[f'home_goals_post_{t}m'] = ((goals_df[f'time_regular']>=t) & (goals_df[f'time_regular']<=cap_at) & (goals_df[f'side']=='home'))*1\n",
    "            time_features_home_away += [f'home_goals_post_{t}m']\n",
    "\n",
    "            goals_df[f'away_goals_post_{t}m'] = ((goals_df[f'time_regular']>=t) & (goals_df[f'time_regular']<=cap_at) & (goals_df[f'side']=='away'))*1\n",
    "            time_features_home_away += [f'away_goals_post_{t}m']\n",
    "        \n",
    "        \n",
    "        goals_features = goals_df.groupby(['match_ref', 'match_date'])[time_features + time_features_home_away].sum().reset_index()\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Error getting SL data: '+str(error))\n",
    "        break\n",
    "    \n",
    "    \n",
    "    # Get Betfair live football matches\n",
    "    try:\n",
    "        events = []\n",
    "        event_type_id = '[\"1\"]'\n",
    "        market_start_time = (datetime.datetime.now() + datetime.timedelta(hours=-10)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        market_end_time = (datetime.datetime.now() + datetime.timedelta(hours=24)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        inplay = 'true'\n",
    "\n",
    "        user_req='{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/listEvents\",\\\n",
    "                   \"params\": {\"filter\":{\"eventTypeIds\":'+event_type_id+',\\\n",
    "                   \"inPlayOnly\":'+inplay+', \\\n",
    "                   \"marketStartTime\":{\"from\":\"'+market_start_time+'\", \"to\":\"'+market_end_time+'\"}}}, \"id\": 1}'\n",
    "\n",
    "        request = requests.post(bet_url, data=user_req.encode('utf-8'), headers=headers)\n",
    "        events += request.json()['result']\n",
    "        \n",
    "        events_df = pd.DataFrame([[e['event']['id'], e['event']['name']] for e in events], columns=['betfair_id', 'betfair_name'])\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Error getting live matches from Betfair: '+str(error))\n",
    "        break\n",
    "        \n",
    "    \n",
    "    # Match Sporting Life and Betfair data\n",
    "    try:\n",
    "        matches_at_prediction_times['sporting_life_event_name'] = matches_at_prediction_times['team_a_name'] + ' v ' + matches_at_prediction_times['team_b_name']\n",
    "        \n",
    "        events_df['sporting_life_event_name'] = None\n",
    "        events_df['match_ref'] = None\n",
    "\n",
    "        lev_max = 10\n",
    "        for i, n in zip(matches_at_prediction_times['match_ref'], matches_at_prediction_times['sporting_life_event_name']):\n",
    "            for idx, row in events_df.iterrows():\n",
    "                if levenshtein_distance(row['betfair_name'], n) < lev_max:\n",
    "                    events_df.at[idx, 'sporting_life_event_name'] = n\n",
    "                    events_df.at[idx, 'match_ref'] = i\n",
    "        \n",
    "        # if no viable matches then sleep until next match reaches prediction time\n",
    "        if sum(events_df['match_ref'].notnull()) == 0:\n",
    "            print(f'No matches found between Betfair and Sporting Life fixtures, sleeping for {sleep_minutes} minutes')\n",
    "            time.sleep(sleep_minutes*60)\n",
    "            continue\n",
    "        \n",
    "        viable_matches_with_betfair_id = matches_at_prediction_times.merge(events_df, how='left', on=['sporting_life_event_name', 'match_ref'])\n",
    "        viable_matches_with_betfair_id = viable_matches_with_betfair_id[viable_matches_with_betfair_id['betfair_id'].notnull()]\n",
    "        \n",
    "        # if no viable matches then sleep until next match reaches prediction time\n",
    "        if len(viable_matches_with_betfair_id) == 0:\n",
    "            print(f'No predictions due after matching with Betfair data, sleeping for {sleep_minutes} minutes')\n",
    "            time.sleep(sleep_minutes*60)\n",
    "            continue\n",
    "        \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Error matching Sporting Life and Betfair data: '+str(error))\n",
    "        break\n",
    "    \n",
    "    \n",
    "    # Do predictions\n",
    "    try:\n",
    "        viable_matches_with_model_data = viable_matches_with_betfair_id.merge(goals_features, how='left', on=['match_ref', 'match_date'])\n",
    "\n",
    "        for f in time_features + time_features_home_away:\n",
    "            viable_matches_with_model_data[f] = viable_matches_with_model_data[f].fillna(0)\n",
    "        \n",
    "        for t in time_cutoffs:\n",
    "            viable_matches_with_model_data[f'goal_diff_at_{t}'] = viable_matches_with_model_data[f'home_goals_pre_{t}m'] - viable_matches_with_model_data[f'away_goals_pre_{t}m']\n",
    "            viable_matches_with_model_data[f'abs_goal_diff_at_{t}'] = abs(viable_matches_with_model_data[f'goal_diff_at_{t}'])\n",
    "        \n",
    "        # check only include games with no goals data if score is 0 - 0\n",
    "        viable_matches_with_model_data['goals_data_num_goals'] = viable_matches_with_model_data['goals_pre_90m'] + viable_matches_with_model_data['goals_post_90m']\n",
    "        viable_matches_with_model_data['matches_data_num_goals'] = viable_matches_with_model_data['team_a_score'] + viable_matches_with_model_data['team_b_score']\n",
    "        \n",
    "        viable_matches_with_unmatched_goals = viable_matches_with_model_data[viable_matches_with_model_data['goals_data_num_goals'] != viable_matches_with_model_data['matches_data_num_goals']]\n",
    "        viable_matches_with_model_data = viable_matches_with_model_data[viable_matches_with_model_data['goals_data_num_goals'] == viable_matches_with_model_data['matches_data_num_goals']]\n",
    "        \n",
    "        viable_matches_with_model_data['year'] = viable_matches_with_model_data['match_date'].apply(lambda x: x[:4]).astype(int)\n",
    "        viable_matches_with_model_data['month'] = viable_matches_with_model_data['match_date'].apply(lambda x: x[5:7]).astype(int)\n",
    "        \n",
    "        prediction_times = [50, 60, 70, 75, 80, 85]\n",
    "        model_data_with_preds = []\n",
    "        for p in prediction_times:\n",
    "            model_data_sub = viable_matches_with_model_data[viable_matches_with_model_data['next_prediction_time']==p]\n",
    "\n",
    "            train_rc_comp = models_dicts[f'any_goal_post_{p}']['train_rc_comp']\n",
    "\n",
    "            model_data_sub['competition_name_rc'] = model_data_sub['competition_name']\n",
    "            model_data_sub.loc[~model_data_sub['competition_name'].isin(train_rc_comp['competition_name_rc']), 'competition_name_rc'] = 'Other'\n",
    "            model_data_sub = model_data_sub.merge(train_rc_comp, how='left', on='competition_name_rc')\n",
    "\n",
    "            model_data_sub = model_data_sub[model_data_sub[models_dicts[f'any_goal_post_{p}']['features']].isnull().sum(axis=1)==0]\n",
    "\n",
    "            if len(model_data_sub) > 0:\n",
    "                model_data_sub['lm_preds'] = models_dicts[f'any_goal_post_{p}']['lin_mod'].predict(sm.add_constant(model_data_sub[models_dicts[f'any_goal_post_{p}']['features']], has_constant='add'))\n",
    "                model_data_sub['rf_preds'] = models_dicts[f'any_goal_post_{p}']['rf_mod'].predict_proba(model_data_sub[models_dicts[f'any_goal_post_{p}']['features']])[:, 1]\n",
    "                model_data_sub['xgb_preds'] = models_dicts[f'any_goal_post_{p}']['xgb_mod'].predict_proba(model_data_sub[models_dicts[f'any_goal_post_{p}']['features']])[:, 1]\n",
    "\n",
    "            model_data_with_preds.append(model_data_sub)\n",
    "\n",
    "        model_data_with_preds = pd.concat(model_data_with_preds, axis=0, sort=False)\n",
    "        \n",
    "        model_data_with_preds['lm_odds_over'] = 1/model_data_with_preds['lm_preds']\n",
    "        model_data_with_preds['rf_odds_over'] = 1/model_data_with_preds['rf_preds']\n",
    "        model_data_with_preds['xgb_odds_over'] = 1/model_data_with_preds['xgb_preds']\n",
    "\n",
    "        model_data_with_preds['lm_odds_under'] = 1/(1-model_data_with_preds['lm_preds'])\n",
    "        model_data_with_preds['rf_odds_under'] = 1/(1-model_data_with_preds['rf_preds'])\n",
    "        model_data_with_preds['xgb_odds_under'] = 1/(1-model_data_with_preds['xgb_preds'])\n",
    "                \n",
    "        model_data_with_preds = add_betting_details_to_data(model_data_with_preds)\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Error doing predictions: '+str(error))\n",
    "        break\n",
    "        \n",
    "        \n",
    "    # Get Betfair markets\n",
    "    try:\n",
    "        # markets\n",
    "        market_catalogue = []\n",
    "        for idx, row in model_data_with_preds.iterrows():\n",
    "\n",
    "            event_type_id = '[\"1\"]'\n",
    "            match_event_id = '[\"'+row['betfair_id']+'\"]'\n",
    "            market_types = '[\"'+row['market_type']+'\"]'\n",
    "            market_start_time = (datetime.datetime.now() + datetime.timedelta(hours=-24)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            market_end_time = (datetime.datetime.now() + datetime.timedelta(hours=24)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            max_results = str(200)\n",
    "            sort_type = 'FIRST_TO_START'\n",
    "            metadata = '[\"EVENT_TYPE\", \"COMPETITION\", \"EVENT\", \"MARKET_START_TIME\", \"MARKET_DESCRIPTION\", \"RUNNER_DESCRIPTION\"]' #, \"RUNNER_METADATA\"]'\n",
    "            inplay = 'true'\n",
    "\n",
    "            user_req='{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/listMarketCatalogue\",\\\n",
    "                       \"params\": {\"filter\":{\"eventTypeIds\":'+event_type_id+',\"marketTypeCodes\":'+market_types+',\\\n",
    "                       \"inPlayOnly\":'+inplay+', \"eventIds\":'+match_event_id+',  \\\n",
    "                       \"marketStartTime\":{\"from\":\"'+market_start_time+'\", \"to\":\"'+market_end_time+'\"}},\\\n",
    "                       \"sort\":\"'+sort_type+'\", \"maxResults\":\"'+max_results+'\", \"marketProjection\":'+metadata+'}, \"id\": 1}'\n",
    "\n",
    "            request = requests.post(bet_url, data=user_req.encode('utf-8'), headers=headers)\n",
    "\n",
    "            try:\n",
    "                request_result = request.json()['result'][0]\n",
    "                model_data_with_preds.at[idx, 'market_id'] = request_result['marketId']\n",
    "                for s in request_result.get('runners', []):\n",
    "                    if s.get('runnerName') == row['runner_name_over']:\n",
    "                        model_data_with_preds.at[idx, 'selection_id_over'] = s.get('selectionId')\n",
    "                    if s.get('runnerName') == row['runner_name_under']:\n",
    "                        model_data_with_preds.at[idx, 'selection_id_under'] = s.get('selectionId')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            market_catalogue += request.json()['result']\n",
    "        \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Error getting Betfair markets: '+str(error))\n",
    "        break\n",
    "        \n",
    "    \n",
    "    # Get odds for each market\n",
    "    try:\n",
    "        market_books = []\n",
    "        for idx, row in model_data_with_preds.iterrows():\n",
    "\n",
    "            priceProjection = '[\"EX_BEST_OFFERS\"]'\n",
    "            prices_req = '{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/listMarketBook\", \"params\": {\"marketIds\": [\"' + str(row['market_id']) + '\"],\"priceProjection\":{\"priceData\":[\"EX_BEST_OFFERS\"]}}, \"id\": 1}'\n",
    "            request = requests.post(bet_url, data=prices_req.encode('utf-8'), headers=headers)\n",
    "            prices_result = request.json()\n",
    "\n",
    "            try:\n",
    "                prices_dict = prices_result['result'][0]\n",
    "                runners = prices_dict.get('runners', [])\n",
    "                is_delayed = prices_dict.get('isMarketDataDelayed')\n",
    "                delay_time = prices_dict.get('betDelay')\n",
    "                total_matched = prices_dict.get('totalMatched')\n",
    "                total_available = prices_dict.get('totalAvailable')\n",
    "                version = prices_dict.get('version')\n",
    "\n",
    "                for r in runners:\n",
    "\n",
    "                    if r['selectionId'] == row['selection_id_over']:\n",
    "                        \n",
    "                        model_data_with_preds.at[idx, 'is_delayed'] = is_delayed\n",
    "                        model_data_with_preds.at[idx, 'delay_time'] = delay_time\n",
    "                        model_data_with_preds.at[idx, 'total_matched'] = total_matched\n",
    "                        model_data_with_preds.at[idx, 'total_available'] = total_available\n",
    "                        model_data_with_preds.at[idx, 'version'] = version\n",
    "                        \n",
    "                        \n",
    "                        for i, a in enumerate(r.get('ex', {}).get('availableToBack', [])):\n",
    "                            model_data_with_preds.at[idx, f'actual_odds_over_back_{i+1}'] = a['price']\n",
    "                            model_data_with_preds.at[idx, f'size_over_back_{i+1}'] = a['size']\n",
    "                        for i, a in enumerate(r.get('ex', {}).get('availableToLay', [])):\n",
    "                            model_data_with_preds.at[idx, f'actual_odds_over_lay_{i+1}'] = a['price']\n",
    "                            model_data_with_preds.at[idx, f'size_over_lay_{i+1}'] = a['size']\n",
    "\n",
    "                    if r['selectionId'] == row['selection_id_under']:\n",
    "                        \n",
    "                        model_data_with_preds.at[idx, 'is_delayed'] = is_delayed\n",
    "                        model_data_with_preds.at[idx, 'delay_time'] = delay_time\n",
    "                        model_data_with_preds.at[idx, 'total_matched'] = total_matched\n",
    "                        model_data_with_preds.at[idx, 'total_available'] = total_available\n",
    "                        model_data_with_preds.at[idx, 'version'] = version\n",
    "                        \n",
    "                        for i, a in enumerate(r.get('ex', {}).get('availableToBack', [])):\n",
    "                            model_data_with_preds.at[idx, f'actual_odds_under_back_{i+1}'] = a['price']\n",
    "                            model_data_with_preds.at[idx, f'size_under_back_{i+1}'] = a['size']\n",
    "                        for i, a in enumerate(r.get('ex', {}).get('availableToLay', [])):\n",
    "                            model_data_with_preds.at[idx, f'actual_odds_under_lay_{i+1}'] = a['price']\n",
    "                            model_data_with_preds.at[idx, f'size_under_lay_{i+1}'] = a['size']\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            market_books.append(prices_dict)\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Error getting Betfair odds: '+str(error))\n",
    "        break\n",
    "    \n",
    "    \n",
    "    # Place bets\n",
    "    try:\n",
    "        # Constraints\n",
    "        back_lay_max_pc = 0.1\n",
    "        odds_gap_min = 0\n",
    "        reduce_price_by_pc = 0\n",
    "        max_bet = 1\n",
    "        \n",
    "        model_data_with_preds['action'] = 'None'\n",
    "\n",
    "        model_data_with_preds.loc[\n",
    "            (model_data_with_preds['lm_odds_over']*(1+odds_gap_min)<model_data_with_preds['actual_odds_over_back_1']) &\n",
    "            (model_data_with_preds['rf_odds_over']*(1+odds_gap_min)<model_data_with_preds['actual_odds_over_back_1']) &\n",
    "            (model_data_with_preds['actual_odds_over_lay_1']/model_data_with_preds['actual_odds_over_back_1'] < (1 + back_lay_max_pc)), 'action'] = 'over'\n",
    "\n",
    "        model_data_with_preds.loc[\n",
    "            (model_data_with_preds['lm_odds_under']*(1+odds_gap_min)<model_data_with_preds['actual_odds_under_back_1']) &\n",
    "            (model_data_with_preds['rf_odds_under']*(1+odds_gap_min)<model_data_with_preds['actual_odds_under_back_1']) &\n",
    "            (model_data_with_preds['actual_odds_under_lay_1']/model_data_with_preds['actual_odds_under_back_1'] < (1 + back_lay_max_pc)), 'action'] = 'under'\n",
    "        \n",
    "        # Placeholder for placing bets\n",
    "        total_bets = sum(model_data_with_preds[\"action\"] != \"None\")\n",
    "        print(f'Found {total_bets} bets, attempting to place')\n",
    "        \n",
    "        order_requests = []\n",
    "        order_results = []\n",
    "        order_fails = pd.DataFrame([], columns=['market_id', 'selection_id', 'available', 'bet_size', 'price', 'min_fill_size', 'market_version'])\n",
    "        for idx, row in model_data_with_preds.iterrows():\n",
    "            \n",
    "            # NOTE: To add in additional lower prices to increase bet amount, can take into account sizes 2 and 3 and odds 2 and 3 \n",
    "            \n",
    "            if row['action'] == 'over':\n",
    "                \n",
    "                market_id = str(row['market_id'])\n",
    "                selection_id = str(row['selection_id_over'])\n",
    "                available = row['size_over_back_1']\n",
    "                bet_size = str(min(available, max_bet))\n",
    "                bf_price = row['actual_odds_over_back_3']\n",
    "                lm_price = row['lm_odds_over']*(1+odds_gap_min)\n",
    "                rf_price = row['rf_odds_over']*(1+odds_gap_min)\n",
    "                price = str(get_valid_price(max(lm_price, rf_price)))\n",
    "                min_fill_size = str(1)\n",
    "                \n",
    "                order_request = {\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/placeOrders\",\n",
    "                                \"params\": {\"marketId\": market_id, \"instructions\": [\n",
    "                                {\"selectionId\": selection_id, \"handicap\": \"0\", \"side\": \"BACK\", \"orderType\": \"LIMIT\",\n",
    "                                \"limitOrder\": {\"size\": bet_size, \"price\": price, \"persistenceType\": \"LAPSE\",\n",
    "                                \"timeInForce\": \"FILL_OR_KILL\", \"minFillSize\": min_fill_size}}]}, \"id\": 1}\n",
    "                \n",
    "                order_requests.append(order_request)\n",
    "                \n",
    "            \n",
    "            if row['action'] == 'under':\n",
    "                \n",
    "                market_id = str(row['market_id'])\n",
    "                selection_id = str(row['selection_id_under'])\n",
    "                available = row['size_under_back_1']\n",
    "                bet_size = str(min(available, max_bet))\n",
    "                bf_price = row['actual_odds_under_back_3']\n",
    "                lm_price = row['lm_odds_under']*(1+odds_gap_min)\n",
    "                rf_price = row['rf_odds_under']*(1+odds_gap_min)\n",
    "                price = str(get_valid_price(max(lm_price, rf_price)))\n",
    "                min_fill_size = str(1)\n",
    "                \n",
    "                order_request = {\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/placeOrders\",\n",
    "                                \"params\": {\"marketId\": market_id, \"instructions\": [\n",
    "                                {\"selectionId\": selection_id, \"handicap\": \"0\", \"side\": \"BACK\", \"orderType\": \"LIMIT\",\n",
    "                                \"limitOrder\": {\"size\": bet_size, \"price\": price, \"persistenceType\": \"LAPSE\",\n",
    "                                \"timeInForce\": \"FILL_OR_KILL\", \"minFillSize\": min_fill_size}}]}, \"id\": 1}\n",
    "                \n",
    "                order_requests.append(order_request)\n",
    "        \n",
    "        try:\n",
    "            if len(order_requests) > 0:\n",
    "                order_requests = str(order_requests).replace(\"'\", '\"')\n",
    "                request = requests.post(bet_url, data=order_requests.encode('utf-8'), headers=headers, timeout=30)\n",
    "                order_results = request.json()\n",
    "        except:\n",
    "            model_data_with_preds_over = model_data_with_preds.loc[model_data_with_preds['action']=='over', ['market_id', 'selection_id_over', 'size_over_back_1', 'actual_odds_over_back_3']].rename(\n",
    "                columns={'selection_id_over': 'selection_id', 'size_over_back_1': 'available', 'actual_odds_over_back_3': 'price'})\n",
    "            model_data_with_preds_under = model_data_with_preds.loc[model_data_with_preds['action']=='under', ['market_id', 'selection_id_under', 'size_under_back_1', 'actual_odds_under_back_3']].rename(\n",
    "                columns={'selection_id_under': 'selection_id', 'size_under_back_1': 'available', 'actual_odds_under_back_3': 'price'})\n",
    "            order_fails = pd.concat([model_data_with_preds_over, model_data_with_preds_under], axis=0).astype(str)\n",
    "            order_fails['bet_size'] = str(1)\n",
    "            order_fails['min_fill_size'] = str(1)\n",
    "            order_fails['market_version'] = str(1)\n",
    "                    \n",
    "        order_results_df = []\n",
    "        for o in order_results:\n",
    "            order_results_df.append(parse_order_result(o['result']))\n",
    "        order_results_df = pd.DataFrame(order_results_df, columns=order_cols)\n",
    "        order_fails_df = order_fails[['market_id', 'selection_id', 'available', 'bet_size', 'price', 'min_fill_size', 'market_version']]\n",
    "        \n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Error placing bets: '+str(error))\n",
    "        break\n",
    "    \n",
    "    \n",
    "    # Send data to database\n",
    "    try:\n",
    "        current_datetime_utc = datetime.datetime.utcnow()\n",
    "        \n",
    "        matches_df['datetime_utc'] = current_datetime_utc\n",
    "        matches_at_prediction_times['datetime_utc'] = current_datetime_utc\n",
    "        matches_pre_prediction_times['datetime_utc'] = current_datetime_utc\n",
    "        events_df['datetime_utc'] = current_datetime_utc\n",
    "        viable_matches_with_betfair_id['datetime_utc'] = current_datetime_utc\n",
    "        viable_matches_with_model_data['datetime_utc'] = current_datetime_utc\n",
    "        viable_matches_with_unmatched_goals['datetime_utc'] = current_datetime_utc\n",
    "        model_data_with_preds['datetime_utc'] = current_datetime_utc\n",
    "        order_results_df['datetime_utc'] = current_datetime_utc\n",
    "        order_fails_df['datetime_utc'] = current_datetime_utc\n",
    "        \n",
    "        connect_string = 'mysql+pymysql://root:'+dbpw+'@localhost/betfair'\n",
    "        sql_engine = sqlalchemy.create_engine(connect_string)\n",
    "        \n",
    "        matches_df.to_sql(name='testing_live_matches_df', con=sql_engine, schema='sl_bf_late_goals', if_exists='append', index=False)\n",
    "        matches_at_prediction_times.to_sql(name='testing_live_matches_at_prediction_times', con=sql_engine, schema='sl_bf_late_goals', if_exists='append', index=False)\n",
    "        matches_pre_prediction_times.to_sql(name='testing_live_matches_pre_prediction_times', con=sql_engine, schema='sl_bf_late_goals', if_exists='append', index=False)\n",
    "        events_df.to_sql(name='testing_live_events_df', con=sql_engine, schema='sl_bf_late_goals', if_exists='append', index=False)\n",
    "        viable_matches_with_betfair_id.to_sql(name='testing_live_viable_matches', con=sql_engine, schema='sl_bf_late_goals', if_exists='append', index=False)\n",
    "        viable_matches_with_model_data.to_sql(name='testing_live_viable_matches_with_model_data', con=sql_engine, schema='sl_bf_late_goals', if_exists='append', index=False)\n",
    "        viable_matches_with_unmatched_goals.to_sql(name='testing_live_viable_matches_with_unmatched_goals', con=sql_engine, schema='sl_bf_late_goals', if_exists='append', index=False)\n",
    "        model_data_with_preds.to_sql(name='testing_live_model_data_with_preds', con=sql_engine, schema='sl_bf_late_goals', if_exists='append', index=False)\n",
    "        order_results_df.to_sql(name='testing_live_order_results', con=sql_engine, schema='sl_bf_late_goals', if_exists='append', index=False)\n",
    "        order_fails_df.to_sql(name='testing_live_order_fails', con=sql_engine, schema='sl_bf_late_goals', if_exists='append', index=False)\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Error sending data to dbs: '+str(error))\n",
    "        break\n",
    "    \n",
    "    \n",
    "    # Finally sleep until the next\n",
    "    end_time = time.time()\n",
    "    print(f'Iteration complete, total time taken {round(end_time - start_time, 1)}s')\n",
    "    print(f'Sleeping for {sleep_minutes} minutes')\n",
    "    time.sleep(sleep_minutes*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To add/test\n",
    "* Selecting prices and checking for min price, handling nulls\n",
    "* Placing multiple orders at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
