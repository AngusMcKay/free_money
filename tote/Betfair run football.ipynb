{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betfair Run Football"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook\n",
    "import datetime\n",
    "import time\n",
    "import importlib\n",
    "import config\n",
    "importlib.reload(config)\n",
    "from config import username, password, application, dbpw, supw\n",
    "import logging\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pymysql\n",
    "import sqlalchemy\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import bf_helpers as bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='bf_places_log.log', level=logging.INFO, format='%(asctime)s, %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# football models\n",
    "with open('/home/angus/projects/betting/tote/models/football_models_2.pickle', 'rb') as f:\n",
    "    football_models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# football secondary models\n",
    "with open('/home/angus/projects/betting/tote/models/football_models_2_secondary_layer.pickle', 'rb') as f:\n",
    "    football_models_secondary_layer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'X-Application': application, 'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "auth = 'username='+username+'&password='+password\n",
    "bet_url = \"https://api.betfair.com/exchange/betting/json-rpc/v1\"\n",
    "allow_subsequent_bets_on_same_runner = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and useful lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = ['', 'AD', 'AE', 'AG', 'AL', 'AM', 'AO', 'AR', 'AT', 'AU', 'AW', 'AZ', 'BA', 'BB', 'BD', 'BE', 'BG', 'BH', 'BN', 'BO', 'BR', 'BY',\n",
    "                 'CA', 'CH', 'CL', 'CM', 'CN', 'CO', 'CR', 'CS', 'CY', 'CZ', 'DE', 'DK', 'DZ', 'EC', 'EE', 'EG', 'ES', 'ET',\n",
    "                 'FI', 'FJ', 'FO', 'FR', 'GB', 'GE', 'GI', 'GR', 'GT', 'GY', 'HK', 'HN', 'HR', 'HU', 'IE', 'IL',\n",
    "                 'IN', 'IS', 'IT', 'JM', 'JO', 'JP', 'KE', 'KH', 'KR', 'KW', 'KZ', 'LI', 'LT', 'LU', 'LV', 'MA',\n",
    "                 'MD', 'MK', 'MO', 'MT', 'MX', 'MY', 'NL', 'NO', 'NZ', 'PA', 'PE', 'PL', 'PS', 'PT', 'PY', 'QA',\n",
    "                 'RO', 'RU', 'RW', 'SA', 'SE', 'SG', 'SI', 'SK', 'SM', 'SV', 'TH', 'TN', 'TR', 'UA', 'US', 'UY',\n",
    "                 'UZ', 'VE', 'VG', 'VN', 'ZA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_market_details(market_cat_entry):\n",
    "    \n",
    "    description = market_cat_entry.get('description', {})\n",
    "    event = market_cat_entry.get('event', {})\n",
    "    event_type = market_cat_entry.get('eventType', {})\n",
    "    competition = market_cat_entry.get('competition', {})\n",
    "    \n",
    "    return [\n",
    "        market_cat_entry.get('marketId', None),\n",
    "        market_cat_entry.get('marketStartTime', None),\n",
    "        description.get('bspMarket', None),\n",
    "        description.get('turnInPlayEnabled', None),\n",
    "        description.get('persistenceEnabled', None),\n",
    "        description.get('marketBaseRate', None),\n",
    "        event.get('id', None),\n",
    "        event.get('name', None),\n",
    "        competition.get('id', None),\n",
    "        competition.get('name', None),\n",
    "        event_type.get('id', None),\n",
    "        description.get('raceType', None),\n",
    "        description.get('bettingType', None),\n",
    "        description.get('marketType', None),\n",
    "        description.get('marketTime', None),\n",
    "        description.get('suspendTime', None),\n",
    "        description.get('bspReconciled', None),\n",
    "        description.get('complete', None),\n",
    "        description.get('inPlay', None),\n",
    "        str(description.get('regulator', None)),\n",
    "        event.get('venue', None),\n",
    "        event.get('countryCode', None),\n",
    "        description.get('discountAllowed', None),\n",
    "        event.get('timezone', None),\n",
    "        event.get('openDate', None),\n",
    "        market_cat_entry.get('marketName', None)\n",
    "    ]\n",
    "\n",
    "\n",
    "def parse_runners(market_cat_entry):\n",
    "\n",
    "    market_id = market_cat_entry.get('marketId', None)\n",
    "    \n",
    "    runners = market_cat_entry.get('runners', {})\n",
    "    runners_list = []\n",
    "    for r in runners:\n",
    "        r_id = r.get('selectionId', None)\n",
    "        r_name = r.get('runnerName', None)\n",
    "        handicap = r.get('handicap', None)\n",
    "        sort_priority = r.get('sortPriority', None)\n",
    "        runners_list.append([r_id, r_name, handicap, sort_priority, market_id])\n",
    "    \n",
    "    return runners_list\n",
    "\n",
    "md_cols = [\n",
    "    'market_id',\n",
    "    'market_start_time',\n",
    "    'bsp_market',\n",
    "    'in_play_enabled',\n",
    "    'persistence_enabled',\n",
    "    'market_base_rate',\n",
    "    'event_id',\n",
    "    'event_name',\n",
    "    'competition_id',\n",
    "    'competition_name',\n",
    "    'event_type_id',\n",
    "    'race_type',\n",
    "    'betting_type',\n",
    "    'market_type',\n",
    "    'market_time',\n",
    "    'suspend_time',\n",
    "    'bsp_reconciled',\n",
    "    'complete',\n",
    "    'in_play',\n",
    "    'regulator',\n",
    "    'venue',\n",
    "    'country_code',\n",
    "    'discount_allowed',\n",
    "    'timezone',\n",
    "    'open_date',\n",
    "    'market_name'\n",
    "]\n",
    "\n",
    "r_cols = ['runner_id', 'runner_name', 'handicap', 'sort_priority', 'market_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_market_book(market_book):\n",
    "    \n",
    "    return [\n",
    "        market_book.get('marketId', None),\n",
    "        market_book.get('isMarketDataDelayed', None),\n",
    "        market_book.get('status', None),\n",
    "        market_book.get('betDelay', None),\n",
    "        market_book.get('bspReconciled', None),\n",
    "        market_book.get('complete', None),\n",
    "        market_book.get('inplay', None),\n",
    "        market_book.get('numberOfWinners', None),\n",
    "        market_book.get('numberOfRunners', None),\n",
    "        market_book.get('numberOfActiveRunners', None),\n",
    "        market_book.get('lastMatchTime', None),\n",
    "        market_book.get('totalMatched', None),\n",
    "        market_book.get('totalAvailable', None),\n",
    "        market_book.get('crossMatching', None),\n",
    "        market_book.get('runnersVoidable', None),\n",
    "        market_book.get('version', None)\n",
    "    ]\n",
    "\n",
    "def parse_market_odds(market_book):\n",
    "    \n",
    "    market_id = market_book.get('marketId', None)\n",
    "    \n",
    "    runners = market_book.get('runners', {})\n",
    "    runners_list = []\n",
    "    for r in runners:\n",
    "        r_id = r.get('selectionId', None)\n",
    "        handicap = r.get('handicap', None)\n",
    "        status = r.get('status', None)\n",
    "        ltp = r.get('lastPriceTraded', None)\n",
    "        total_matched = r.get('totalMatched', None)\n",
    "        \n",
    "        ex_back = r.get('ex', {}).get('availableToBack', [])\n",
    "        back_prices = [None, None, None]\n",
    "        back_sizes = [None, None, None]\n",
    "        for i, b in enumerate(ex_back[:3]):\n",
    "            back_prices[i] = b.get('price', None)\n",
    "            back_sizes[i] = b.get('size', None)\n",
    "        \n",
    "        ex_lay = r.get('ex', {}).get('availableToLay', [])\n",
    "        lay_prices = [None, None, None]\n",
    "        lay_sizes = [None, None, None]\n",
    "        for i, l in enumerate(ex_lay[:3]):\n",
    "            lay_prices[i] = l.get('price', None)\n",
    "            lay_sizes[i] = l.get('size', None)\n",
    "        \n",
    "        runners_list.append([r_id, handicap, status, ltp, total_matched] + back_prices + back_sizes + lay_prices + lay_sizes + [market_id])    \n",
    "    \n",
    "    return runners_list\n",
    "\n",
    "mb_cols = [\n",
    "    'market_id',\n",
    "    'is_market_data_delayed',\n",
    "    'market_status',\n",
    "    'bet_delay',\n",
    "    'bsp_reconciled',\n",
    "    'complete',\n",
    "    'inplay',\n",
    "    'number_of_winners',\n",
    "    'number_of_runners',\n",
    "    'number_of_active_runners',\n",
    "    'last_match_time',\n",
    "    'total_matched',\n",
    "    'total_available',\n",
    "    'cross_matching',\n",
    "    'runners_voidable',\n",
    "    'version'\n",
    "]\n",
    "\n",
    "odds_cols = [\n",
    "    'runner_id', 'handicap', 'status', 'ltp', 'total_matched',\n",
    "    'back_price_1', 'back_price_2', 'back_price_3', 'back_size_1', 'back_size_2', 'back_size_3',\n",
    "    'lay_price_1', 'lay_price_2', 'lay_price_3', 'lay_size_1', 'lay_size_2', 'lay_size_3',\n",
    "    'market_id'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_definition_columns = [\n",
    "    'market_id', 'market_start_time', 'market_time', 'suspend_time', 'open_date', 'api_call_time_utc', 'minutes_to_event',\n",
    "    'event_id', 'venue', 'event_name', 'competition_id', 'competition_name', 'race_type', 'market_name', 'market_type', 'event_type_id', 'betting_type', 'country_code', 'timezone',\n",
    "    'bsp_market', 'in_play_enabled', 'persistence_enabled', 'market_base_rate', 'regulator', 'discount_allowed'\n",
    "]\n",
    "\n",
    "market_book_columns = [\n",
    "    'market_id', 'number_of_winners', 'number_of_runners', 'number_of_active_runners',\n",
    "    'last_match_time', 'total_matched', 'total_available', 'cross_matching', 'runners_voidable', 'version',\n",
    "    'is_market_data_delayed', 'market_status', 'bet_delay', 'bsp_reconciled', 'complete', 'inplay'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner_cols = [\n",
    "    'runner_id', 'runner_name', 'market_id', 'sort_priority', 'api_call_time_utc'\n",
    "]\n",
    "\n",
    "market_odds_cols = [\n",
    "    'runner_id', 'handicap', 'status', 'market_id', 'ltp', 'total_matched',\n",
    "    'back_price_1', 'back_price_2', 'back_price_3', 'back_size_1', 'back_size_2', 'back_size_3',\n",
    "    'lay_price_1', 'lay_price_2', 'lay_price_3', 'lay_size_1', 'lay_size_2', 'lay_size_3'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_markets = [\n",
    "    'CORRECT_SCORE 0 - 0 - ltp', 'CORRECT_SCORE 0 - 1 - ltp',\n",
    "    'CORRECT_SCORE 0 - 2 - ltp', 'CORRECT_SCORE 0 - 3 - ltp',\n",
    "    'CORRECT_SCORE 1 - 0 - ltp', 'CORRECT_SCORE 1 - 1 - ltp',\n",
    "    'CORRECT_SCORE 1 - 2 - ltp', 'CORRECT_SCORE 1 - 3 - ltp',\n",
    "    'CORRECT_SCORE 2 - 0 - ltp', 'CORRECT_SCORE 2 - 1 - ltp',\n",
    "    'CORRECT_SCORE 2 - 2 - ltp', 'CORRECT_SCORE 2 - 3 - ltp',\n",
    "    'CORRECT_SCORE 3 - 0 - ltp', 'CORRECT_SCORE 3 - 1 - ltp',\n",
    "    'CORRECT_SCORE 3 - 2 - ltp', 'CORRECT_SCORE 3 - 3 - ltp',\n",
    "    'MATCH_ODDS Away - ltp', 'MATCH_ODDS Home - ltp', 'MATCH_ODDS The Draw - ltp',\n",
    "    'OVER_UNDER_05 Over 0.5 Goals - ltp', 'OVER_UNDER_05 Under 0.5 Goals - ltp',\n",
    "    'OVER_UNDER_15 Over 1.5 Goals - ltp', 'OVER_UNDER_15 Under 1.5 Goals - ltp',\n",
    "    'OVER_UNDER_25 Over 2.5 Goals - ltp', 'OVER_UNDER_25 Under 2.5 Goals - ltp',\n",
    "    'OVER_UNDER_35 Over 3.5 Goals - ltp', 'OVER_UNDER_35 Under 3.5 Goals - ltp',\n",
    "    'OVER_UNDER_45 Over 4.5 Goals - ltp', 'OVER_UNDER_45 Under 4.5 Goals - ltp'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_order_result(order_result):\n",
    "    instruction_report = order_result.get('instructionReports', [{}])[0]\n",
    "    instruction = instruction_report.get('instruction', {})\n",
    "    limit_order = instruction.get('limitOrder', {})\n",
    "    \n",
    "    return [\n",
    "        order_result.get('status', None),\n",
    "        order_result.get('marketId', None),\n",
    "        instruction.get('selectionId', None),\n",
    "        instruction.get('handicap', None),\n",
    "        limit_order.get('size', None),\n",
    "        limit_order.get('price', None),\n",
    "        limit_order.get('timeInForce', None),\n",
    "        limit_order.get('minFillSize', None),\n",
    "        instruction.get('orderType', None),\n",
    "        instruction.get('side', None),\n",
    "        instruction_report.get('errorCode', None),\n",
    "        instruction_report.get('betId', None),\n",
    "        instruction_report.get('placedDate', None),\n",
    "        instruction_report.get('averagePriceMatched', None),\n",
    "        instruction_report.get('sizeMatched', None),\n",
    "        instruction_report.get('orderStatus', None)\n",
    "    ]\n",
    "    \n",
    "order_cols = ['status', 'market_id', 'selection_id', 'handicap', 'size', 'price', 'time_in_force', 'min_fill_size',\n",
    "              'order_type', 'side', 'error_code', 'bet_id', 'placed_date', 'average_price_matched', 'size_matched', 'order_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_output_cols = ['event_id',\n",
    " 'event_name',\n",
    " 'CORRECT_SCORE 0 - 0 - ltp',\n",
    " 'CORRECT_SCORE 0 - 1 - ltp',\n",
    " 'CORRECT_SCORE 0 - 2 - ltp',\n",
    " 'CORRECT_SCORE 0 - 3 - ltp',\n",
    " 'CORRECT_SCORE 1 - 0 - ltp',\n",
    " 'CORRECT_SCORE 1 - 1 - ltp',\n",
    " 'CORRECT_SCORE 1 - 2 - ltp',\n",
    " 'CORRECT_SCORE 1 - 3 - ltp',\n",
    " 'CORRECT_SCORE 2 - 0 - ltp',\n",
    " 'CORRECT_SCORE 2 - 1 - ltp',\n",
    " 'CORRECT_SCORE 2 - 2 - ltp',\n",
    " 'CORRECT_SCORE 2 - 3 - ltp',\n",
    " 'CORRECT_SCORE 3 - 0 - ltp',\n",
    " 'CORRECT_SCORE 3 - 1 - ltp',\n",
    " 'CORRECT_SCORE 3 - 2 - ltp',\n",
    " 'CORRECT_SCORE 3 - 3 - ltp',\n",
    " 'CORRECT_SCORE Any Other Away Win - ltp',\n",
    " 'CORRECT_SCORE Any Other Draw - ltp',\n",
    " 'CORRECT_SCORE Any Other Home Win - ltp',\n",
    " 'MATCH_ODDS Away - ltp',\n",
    " 'MATCH_ODDS Home - ltp',\n",
    " 'MATCH_ODDS The Draw - ltp',\n",
    " 'OVER_UNDER_05 Over 0.5 Goals - ltp',\n",
    " 'OVER_UNDER_05 Under 0.5 Goals - ltp',\n",
    " 'OVER_UNDER_15 Over 1.5 Goals - ltp',\n",
    " 'OVER_UNDER_15 Under 1.5 Goals - ltp',\n",
    " 'OVER_UNDER_25 Over 2.5 Goals - ltp',\n",
    " 'OVER_UNDER_25 Under 2.5 Goals - ltp',\n",
    " 'OVER_UNDER_35 Over 3.5 Goals - ltp',\n",
    " 'OVER_UNDER_35 Under 3.5 Goals - ltp',\n",
    " 'OVER_UNDER_45 Over 4.5 Goals - ltp',\n",
    " 'OVER_UNDER_45 Under 4.5 Goals - ltp',\n",
    " 'CORRECT_SCORE 0 - 0 - market_id',\n",
    " 'CORRECT_SCORE 0 - 1 - market_id',\n",
    " 'CORRECT_SCORE 0 - 2 - market_id',\n",
    " 'CORRECT_SCORE 0 - 3 - market_id',\n",
    " 'CORRECT_SCORE 1 - 0 - market_id',\n",
    " 'CORRECT_SCORE 1 - 1 - market_id',\n",
    " 'CORRECT_SCORE 1 - 2 - market_id',\n",
    " 'CORRECT_SCORE 1 - 3 - market_id',\n",
    " 'CORRECT_SCORE 2 - 0 - market_id',\n",
    " 'CORRECT_SCORE 2 - 1 - market_id',\n",
    " 'CORRECT_SCORE 2 - 2 - market_id',\n",
    " 'CORRECT_SCORE 2 - 3 - market_id',\n",
    " 'CORRECT_SCORE 3 - 0 - market_id',\n",
    " 'CORRECT_SCORE 3 - 1 - market_id',\n",
    " 'CORRECT_SCORE 3 - 2 - market_id',\n",
    " 'CORRECT_SCORE 3 - 3 - market_id',\n",
    " 'CORRECT_SCORE Any Other Away Win - market_id',\n",
    " 'CORRECT_SCORE Any Other Draw - market_id',\n",
    " 'CORRECT_SCORE Any Other Home Win - market_id',\n",
    " 'MATCH_ODDS Away - market_id',\n",
    " 'MATCH_ODDS Home - market_id',\n",
    " 'MATCH_ODDS The Draw - market_id',\n",
    " 'OVER_UNDER_05 Over 0.5 Goals - market_id',\n",
    " 'OVER_UNDER_05 Under 0.5 Goals - market_id',\n",
    " 'OVER_UNDER_15 Over 1.5 Goals - market_id',\n",
    " 'OVER_UNDER_15 Under 1.5 Goals - market_id',\n",
    " 'OVER_UNDER_25 Over 2.5 Goals - market_id',\n",
    " 'OVER_UNDER_25 Under 2.5 Goals - market_id',\n",
    " 'OVER_UNDER_35 Over 3.5 Goals - market_id',\n",
    " 'OVER_UNDER_35 Under 3.5 Goals - market_id',\n",
    " 'OVER_UNDER_45 Over 4.5 Goals - market_id',\n",
    " 'OVER_UNDER_45 Under 4.5 Goals - market_id',\n",
    " 'CORRECT_SCORE 0 - 0 - runner_id',\n",
    " 'CORRECT_SCORE 0 - 1 - runner_id',\n",
    " 'CORRECT_SCORE 0 - 2 - runner_id',\n",
    " 'CORRECT_SCORE 0 - 3 - runner_id',\n",
    " 'CORRECT_SCORE 1 - 0 - runner_id',\n",
    " 'CORRECT_SCORE 1 - 1 - runner_id',\n",
    " 'CORRECT_SCORE 1 - 2 - runner_id',\n",
    " 'CORRECT_SCORE 1 - 3 - runner_id',\n",
    " 'CORRECT_SCORE 2 - 0 - runner_id',\n",
    " 'CORRECT_SCORE 2 - 1 - runner_id',\n",
    " 'CORRECT_SCORE 2 - 2 - runner_id',\n",
    " 'CORRECT_SCORE 2 - 3 - runner_id',\n",
    " 'CORRECT_SCORE 3 - 0 - runner_id',\n",
    " 'CORRECT_SCORE 3 - 1 - runner_id',\n",
    " 'CORRECT_SCORE 3 - 2 - runner_id',\n",
    " 'CORRECT_SCORE 3 - 3 - runner_id',\n",
    " 'CORRECT_SCORE Any Other Away Win - runner_id',\n",
    " 'CORRECT_SCORE Any Other Draw - runner_id',\n",
    " 'CORRECT_SCORE Any Other Home Win - runner_id',\n",
    " 'MATCH_ODDS Away - runner_id',\n",
    " 'MATCH_ODDS Home - runner_id',\n",
    " 'MATCH_ODDS The Draw - runner_id',\n",
    " 'OVER_UNDER_05 Over 0.5 Goals - runner_id',\n",
    " 'OVER_UNDER_05 Under 0.5 Goals - runner_id',\n",
    " 'OVER_UNDER_15 Over 1.5 Goals - runner_id',\n",
    " 'OVER_UNDER_15 Under 1.5 Goals - runner_id',\n",
    " 'OVER_UNDER_25 Over 2.5 Goals - runner_id',\n",
    " 'OVER_UNDER_25 Under 2.5 Goals - runner_id',\n",
    " 'OVER_UNDER_35 Over 3.5 Goals - runner_id',\n",
    " 'OVER_UNDER_35 Under 3.5 Goals - runner_id',\n",
    " 'OVER_UNDER_45 Over 4.5 Goals - runner_id',\n",
    " 'OVER_UNDER_45 Under 4.5 Goals - runner_id',\n",
    " 'CORRECT_SCORE 0 - 0 - runner_name',\n",
    " 'CORRECT_SCORE 0 - 1 - runner_name',\n",
    " 'CORRECT_SCORE 0 - 2 - runner_name',\n",
    " 'CORRECT_SCORE 0 - 3 - runner_name',\n",
    " 'CORRECT_SCORE 1 - 0 - runner_name',\n",
    " 'CORRECT_SCORE 1 - 1 - runner_name',\n",
    " 'CORRECT_SCORE 1 - 2 - runner_name',\n",
    " 'CORRECT_SCORE 1 - 3 - runner_name',\n",
    " 'CORRECT_SCORE 2 - 0 - runner_name',\n",
    " 'CORRECT_SCORE 2 - 1 - runner_name',\n",
    " 'CORRECT_SCORE 2 - 2 - runner_name',\n",
    " 'CORRECT_SCORE 2 - 3 - runner_name',\n",
    " 'CORRECT_SCORE 3 - 0 - runner_name',\n",
    " 'CORRECT_SCORE 3 - 1 - runner_name',\n",
    " 'CORRECT_SCORE 3 - 2 - runner_name',\n",
    " 'CORRECT_SCORE 3 - 3 - runner_name',\n",
    " 'CORRECT_SCORE Any Other Away Win - runner_name',\n",
    " 'CORRECT_SCORE Any Other Draw - runner_name',\n",
    " 'CORRECT_SCORE Any Other Home Win - runner_name',\n",
    " 'MATCH_ODDS Away - runner_name',\n",
    " 'MATCH_ODDS Home - runner_name',\n",
    " 'MATCH_ODDS The Draw - runner_name',\n",
    " 'OVER_UNDER_05 Over 0.5 Goals - runner_name',\n",
    " 'OVER_UNDER_05 Under 0.5 Goals - runner_name',\n",
    " 'OVER_UNDER_15 Over 1.5 Goals - runner_name',\n",
    " 'OVER_UNDER_15 Under 1.5 Goals - runner_name',\n",
    " 'OVER_UNDER_25 Over 2.5 Goals - runner_name',\n",
    " 'OVER_UNDER_25 Under 2.5 Goals - runner_name',\n",
    " 'OVER_UNDER_35 Over 3.5 Goals - runner_name',\n",
    " 'OVER_UNDER_35 Under 3.5 Goals - runner_name',\n",
    " 'OVER_UNDER_45 Over 4.5 Goals - runner_name',\n",
    " 'OVER_UNDER_45 Under 4.5 Goals - runner_name',\n",
    " 'minutes_to_event',\n",
    " 'CORRECT_SCORE 0 - 0 - pred',\n",
    " 'CORRECT_SCORE 0 - 0 - pred_odds',\n",
    " 'CORRECT_SCORE 0 - 1 - pred',\n",
    " 'CORRECT_SCORE 0 - 1 - pred_odds',\n",
    " 'CORRECT_SCORE 0 - 2 - pred',\n",
    " 'CORRECT_SCORE 0 - 2 - pred_odds',\n",
    " 'CORRECT_SCORE 0 - 3 - pred',\n",
    " 'CORRECT_SCORE 0 - 3 - pred_odds',\n",
    " 'CORRECT_SCORE 1 - 0 - pred',\n",
    " 'CORRECT_SCORE 1 - 0 - pred_odds',\n",
    " 'CORRECT_SCORE 1 - 1 - pred',\n",
    " 'CORRECT_SCORE 1 - 1 - pred_odds',\n",
    " 'CORRECT_SCORE 1 - 2 - pred',\n",
    " 'CORRECT_SCORE 1 - 2 - pred_odds',\n",
    " 'CORRECT_SCORE 1 - 3 - pred',\n",
    " 'CORRECT_SCORE 1 - 3 - pred_odds',\n",
    " 'CORRECT_SCORE 2 - 0 - pred',\n",
    " 'CORRECT_SCORE 2 - 0 - pred_odds',\n",
    " 'CORRECT_SCORE 2 - 1 - pred',\n",
    " 'CORRECT_SCORE 2 - 1 - pred_odds',\n",
    " 'CORRECT_SCORE 2 - 2 - pred',\n",
    " 'CORRECT_SCORE 2 - 2 - pred_odds',\n",
    " 'CORRECT_SCORE 2 - 3 - pred',\n",
    " 'CORRECT_SCORE 2 - 3 - pred_odds',\n",
    " 'CORRECT_SCORE 3 - 0 - pred',\n",
    " 'CORRECT_SCORE 3 - 0 - pred_odds',\n",
    " 'CORRECT_SCORE 3 - 1 - pred',\n",
    " 'CORRECT_SCORE 3 - 1 - pred_odds',\n",
    " 'CORRECT_SCORE 3 - 2 - pred',\n",
    " 'CORRECT_SCORE 3 - 2 - pred_odds',\n",
    " 'CORRECT_SCORE 3 - 3 - pred',\n",
    " 'CORRECT_SCORE 3 - 3 - pred_odds',\n",
    " 'MATCH_ODDS Away - pred',\n",
    " 'MATCH_ODDS Away - pred_odds',\n",
    " 'MATCH_ODDS Home - pred',\n",
    " 'MATCH_ODDS Home - pred_odds',\n",
    " 'MATCH_ODDS The Draw - pred',\n",
    " 'MATCH_ODDS The Draw - pred_odds',\n",
    " 'OVER_UNDER_05 Over 0.5 Goals - pred',\n",
    " 'OVER_UNDER_05 Over 0.5 Goals - pred_odds',\n",
    " 'OVER_UNDER_05 Under 0.5 Goals - pred',\n",
    " 'OVER_UNDER_05 Under 0.5 Goals - pred_odds',\n",
    " 'OVER_UNDER_15 Over 1.5 Goals - pred',\n",
    " 'OVER_UNDER_15 Over 1.5 Goals - pred_odds',\n",
    " 'OVER_UNDER_15 Under 1.5 Goals - pred',\n",
    " 'OVER_UNDER_15 Under 1.5 Goals - pred_odds',\n",
    " 'OVER_UNDER_25 Over 2.5 Goals - pred',\n",
    " 'OVER_UNDER_25 Over 2.5 Goals - pred_odds',\n",
    " 'OVER_UNDER_25 Under 2.5 Goals - pred',\n",
    " 'OVER_UNDER_25 Under 2.5 Goals - pred_odds',\n",
    " 'OVER_UNDER_35 Over 3.5 Goals - pred',\n",
    " 'OVER_UNDER_35 Over 3.5 Goals - pred_odds',\n",
    " 'OVER_UNDER_35 Under 3.5 Goals - pred',\n",
    " 'OVER_UNDER_35 Under 3.5 Goals - pred_odds',\n",
    " 'OVER_UNDER_45 Over 4.5 Goals - pred',\n",
    " 'OVER_UNDER_45 Over 4.5 Goals - pred_odds',\n",
    " 'OVER_UNDER_45 Under 4.5 Goals - pred',\n",
    " 'OVER_UNDER_45 Under 4.5 Goals - pred_odds',\n",
    " 'CORRECT_SCORE 0 - 0 - bookie_probs',\n",
    " 'CORRECT_SCORE 0 - 1 - bookie_probs',\n",
    " 'CORRECT_SCORE 0 - 2 - bookie_probs',\n",
    " 'CORRECT_SCORE 0 - 3 - bookie_probs',\n",
    " 'CORRECT_SCORE 1 - 0 - bookie_probs',\n",
    " 'CORRECT_SCORE 1 - 1 - bookie_probs',\n",
    " 'CORRECT_SCORE 1 - 2 - bookie_probs',\n",
    " 'CORRECT_SCORE 1 - 3 - bookie_probs',\n",
    " 'CORRECT_SCORE 2 - 0 - bookie_probs',\n",
    " 'CORRECT_SCORE 2 - 1 - bookie_probs',\n",
    " 'CORRECT_SCORE 2 - 2 - bookie_probs',\n",
    " 'CORRECT_SCORE 2 - 3 - bookie_probs',\n",
    " 'CORRECT_SCORE 3 - 0 - bookie_probs',\n",
    " 'CORRECT_SCORE 3 - 1 - bookie_probs',\n",
    " 'CORRECT_SCORE 3 - 2 - bookie_probs',\n",
    " 'CORRECT_SCORE 3 - 3 - bookie_probs',\n",
    " 'MATCH_ODDS Away - bookie_probs',\n",
    " 'MATCH_ODDS Home - bookie_probs',\n",
    " 'MATCH_ODDS The Draw - bookie_probs',\n",
    " 'OVER_UNDER_05 Over 0.5 Goals - bookie_probs',\n",
    " 'OVER_UNDER_05 Under 0.5 Goals - bookie_probs',\n",
    " 'OVER_UNDER_15 Over 1.5 Goals - bookie_probs',\n",
    " 'OVER_UNDER_15 Under 1.5 Goals - bookie_probs',\n",
    " 'OVER_UNDER_25 Over 2.5 Goals - bookie_probs',\n",
    " 'OVER_UNDER_25 Under 2.5 Goals - bookie_probs',\n",
    " 'OVER_UNDER_35 Over 3.5 Goals - bookie_probs',\n",
    " 'OVER_UNDER_35 Under 3.5 Goals - bookie_probs',\n",
    " 'OVER_UNDER_45 Over 4.5 Goals - bookie_probs',\n",
    " 'OVER_UNDER_45 Under 4.5 Goals - bookie_probs',\n",
    " 'correct_score_overround',\n",
    " 'match_odds_overround',\n",
    " 'over_under_overround']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop to retrieve data, predict outcomes and place bets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "starting process\n",
      "\n",
      "Logged in!\n",
      "Retrieving events\n",
      "Got 382 event ids, time taken 13.01s\n",
      "Retrieving markets\n",
      "Markets retrieved at 2022-01-15 11:59:04.050860 UTC, time taken: 42.22s\n",
      "Parsed 2411 markets\n",
      "Getting odds\n",
      "Time taken: 88.47s\n",
      "Odds retrieved, time taken: 88.47s\n",
      "Prediction data created for 115 events\n",
      "Predictions done\n",
      "Found 0 back bets\n",
      "Found 0 secondary layer bets\n",
      "Data sent to DB\n",
      "Total time taken: 94.848 seconds\n"
     ]
    }
   ],
   "source": [
    "retry_counter = 0\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    print('\\n\\nstarting process')\n",
    "    \n",
    "    \n",
    "    # GET EXISTING BETS FROM DB\n",
    "    connect_string = 'mysql+pymysql://root:'+dbpw+'@localhost/betfair'\n",
    "    sql_engine = sqlalchemy.create_engine(connect_string)\n",
    "    existing_bets = pd.read_sql('''\n",
    "                            SELECT DISTINCT selection_id as runner_id, market_id, side as existing_side, 1 AS existing_bet \n",
    "                            FROM football_order_results_live\n",
    "                            WHERE order_status = 'EXECUTION_COMPLETE'\n",
    "                            AND CAST(left(placed_date,10) AS DATETIME) >= DATE_ADD(curdate(), INTERVAL -2 DAY)\n",
    "                          ''',\n",
    "                          con=sql_engine)\n",
    "    existing_back_bets = existing_bets[existing_bets['existing_side']=='BACK']\n",
    "    existing_lay_bets = existing_bets[existing_bets['existing_side']=='LAY']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # LOGIN\n",
    "    try:\n",
    "\n",
    "        login = requests.post('https://identitysso-cert.betfair.com/api/certlogin',\n",
    "                              cert=('/etc/ssl/client-2048.crt', '/etc/ssl/client-2048.key'),\n",
    "                              headers=header, data=auth, timeout=30)\n",
    "\n",
    "        if login.status_code==503: # Betfair site down code - they don't give expected time so just got to keep trying\n",
    "            logging.error('Login error '+str(login.status_code))\n",
    "            print('\\nLogin error, trying again in 1 minute')\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            login_success = login.json()['loginStatus']\n",
    "            if login_success=='TEMPORARY_BAN_TOO_MANY_REQUESTS':\n",
    "                print(f'Login response is TEMPORARY_BAN_TOO_MANY_REQUESTS so continue with existing ssoid')\n",
    "            elif login_success!='SUCCESS':\n",
    "                print(f'Login unsuccessful due to LoginStatus: {login_success}, try to continue with existing login')\n",
    "            else:\n",
    "                logging.info('Login '+str(login_success))\n",
    "                ssoid = login.json()['sessionToken']\n",
    "                print('\\nLogged in!')\n",
    "\n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Login error: '+str(error))\n",
    "        \n",
    "        if retry_counter < 25:\n",
    "            logging.error('Login error '+str(error))\n",
    "            print('\\nLogin error, trying again in 1 minute - retry counter at '+str(retry_counter))\n",
    "            retry_counter += 1\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "        else:\n",
    "            logging.error('Login error '+str(error))\n",
    "            print('\\nLogin error, attempting to restart network manager and then try again in 1 minute')\n",
    "            os.system('echo '+supw+' | sudo -S service network-manager restart')\n",
    "            retry_counter = 0\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "    \n",
    "    headers = {'X-Application': application, 'X-Authentication': ssoid, 'content-type': 'application/json'}\n",
    "    \n",
    "    \n",
    "    \n",
    "    # GET EVENTS (GETTING WHOLE MARKETS IS TOO MUCH DATA FOR API)\n",
    "    print('Retrieving events')\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        def get_market_catalogue(country):\n",
    "            countries = '[\"'+country+'\"]'\n",
    "            event_type_id = '[\"1\"]'\n",
    "            market_types = '[\"MATCH_ODDS\"]'\n",
    "            market_start_time = (datetime.datetime.now() + datetime.timedelta(hours=-1)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            market_end_time = (datetime.datetime.now() + datetime.timedelta(hours=24)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            max_results = str(200)\n",
    "            sort_type = 'FIRST_TO_START'\n",
    "            metadata = '[\"EVENT\"]'\n",
    "            inplay = 'false'\n",
    "\n",
    "            user_req='{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/listMarketCatalogue\",\\\n",
    "                       \"params\": {\"filter\":{\"eventTypeIds\":'+event_type_id+',\"marketTypeCodes\":'+market_types+',\\\n",
    "                       \"inPlayOnly\":'+inplay+', \"marketCountries\":'+countries+',  \\\n",
    "                       \"marketStartTime\":{\"from\":\"'+market_start_time+'\", \"to\":\"'+market_end_time+'\"}},\\\n",
    "                       \"sort\":\"'+sort_type+'\", \"maxResults\":\"'+max_results+'\", \"marketProjection\":'+metadata+'}, \"id\": 1}'\n",
    "\n",
    "            request = requests.post(bet_url, data=user_req.encode('utf-8'), headers=headers, timeout=30)\n",
    "\n",
    "            return request.json()['result']\n",
    "\n",
    "        p = Pool(4)\n",
    "        market_catalogue_mp = p.imap(get_market_catalogue, all_countries)\n",
    "        p.close()\n",
    "        p.join() # this ensures imap has finished before moving on\n",
    "        market_catalogue = []\n",
    "        for mc in market_catalogue_mp:\n",
    "            market_catalogue += mc\n",
    "\n",
    "        end_time = time.time()\n",
    "        \n",
    "#         market_catalogue = []\n",
    "#         for c in tqdm_notebook(all_countries):\n",
    "\n",
    "#             event_type_id = '[\"1\"]'\n",
    "#             countries = '[\"'+c+'\"]'\n",
    "#             market_types = '[\"MATCH_ODDS\"]'\n",
    "#             market_start_time = (datetime.datetime.now() + datetime.timedelta(hours=-1)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "#             market_end_time = (datetime.datetime.now() + datetime.timedelta(hours=24)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "#             max_results = str(200)\n",
    "#             sort_type = 'FIRST_TO_START'\n",
    "#             metadata = '[\"EVENT\"]' #, \"RUNNER_METADATA\"]'\n",
    "#             inplay = 'false'\n",
    "\n",
    "#             user_req='{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/listMarketCatalogue\",\\\n",
    "#                        \"params\": {\"filter\":{\"eventTypeIds\":'+event_type_id+',\"marketTypeCodes\":'+market_types+',\\\n",
    "#                        \"inPlayOnly\":'+inplay+', \"marketCountries\":'+countries+',  \\\n",
    "#                        \"marketStartTime\":{\"from\":\"'+market_start_time+'\", \"to\":\"'+market_end_time+'\"}},\\\n",
    "#                        \"sort\":\"'+sort_type+'\", \"maxResults\":\"'+max_results+'\", \"marketProjection\":'+metadata+'}, \"id\": 1}'\n",
    "\n",
    "#             request = requests.post(bet_url, data=user_req.encode('utf-8'), headers=headers, timeout=30)\n",
    "#             market_catalogue += request.json()['result']\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Error getting events, trying again in one minute: '+str(error))\n",
    "        logging.error('Error getting events, error: '+str(error))\n",
    "        time.sleep(60)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    all_event_ids = list(set([m.get('event', {}).get('id') for m in market_catalogue if m.get('event', {}).get('id', 'na')!='na']))\n",
    "    print(f'Got {len(all_event_ids)} event ids, time taken {round(end_time - start_time, 2)}s')\n",
    "\n",
    "    \n",
    "    \n",
    "    # GET MARKETS\n",
    "    print('Retrieving markets')\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        def reget_market_catalogue(event_id):\n",
    "            event_type_id = '[\"1\"]'\n",
    "            match_event_id = '[\"'+event_id+'\"]'\n",
    "            market_types = '[\"CORRECT_SCORE\", \"MATCH_ODDS\", \"OVER_UNDER_05\", \"OVER_UNDER_15\", \"OVER_UNDER_25\", \"OVER_UNDER_35\", \"OVER_UNDER_45\"]'\n",
    "            market_start_time = (datetime.datetime.now() + datetime.timedelta(hours=-1)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            market_end_time = (datetime.datetime.now() + datetime.timedelta(hours=24)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            max_results = str(200)\n",
    "            sort_type = 'FIRST_TO_START'\n",
    "            metadata = '[\"EVENT_TYPE\", \"COMPETITION\", \"EVENT\", \"MARKET_START_TIME\", \"MARKET_DESCRIPTION\", \"RUNNER_DESCRIPTION\"]' #, \"RUNNER_METADATA\"]'\n",
    "            inplay = 'false'\n",
    "\n",
    "            user_req='{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/listMarketCatalogue\",\\\n",
    "                       \"params\": {\"filter\":{\"eventTypeIds\":'+event_type_id+',\"marketTypeCodes\":'+market_types+',\\\n",
    "                       \"inPlayOnly\":'+inplay+', \"eventIds\":'+match_event_id+',  \\\n",
    "                       \"marketStartTime\":{\"from\":\"'+market_start_time+'\", \"to\":\"'+market_end_time+'\"}},\\\n",
    "                       \"sort\":\"'+sort_type+'\", \"maxResults\":\"'+max_results+'\", \"marketProjection\":'+metadata+'}, \"id\": 1}'\n",
    "\n",
    "            request = requests.post(bet_url, data=user_req.encode('utf-8'), headers=headers, timeout=30)\n",
    "\n",
    "            return request.json()['result']\n",
    "\n",
    "        p = Pool(4)\n",
    "        market_catalogue_mp = p.imap(reget_market_catalogue, all_event_ids)\n",
    "        p.close()\n",
    "        p.join() # this ensures imap has finished before moving on\n",
    "        market_catalogue = []\n",
    "        for mc in market_catalogue_mp:\n",
    "            market_catalogue += mc\n",
    "\n",
    "        end_time = time.time()\n",
    "        \n",
    "#         market_catalogue = []\n",
    "#         for e in tqdm_notebook(all_event_ids): # Note: these event ids are the football matches, as opposed to event_type_id 1 which means football\n",
    "\n",
    "#             event_type_id = '[\"1\"]'\n",
    "#             #countries = '[\"GB\", \"FR\", \"IT\", \"DE\", \"ES\"]'\n",
    "#             match_event_id = '[\"'+e+'\"]'\n",
    "#             market_types = '[\"CORRECT_SCORE\", \"MATCH_ODDS\", \"OVER_UNDER_05\", \"OVER_UNDER_15\", \"OVER_UNDER_25\", \"OVER_UNDER_35\", \"OVER_UNDER_45\"]'\n",
    "#             market_start_time = (datetime.datetime.now() + datetime.timedelta(hours=-1)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "#             market_end_time = (datetime.datetime.now() + datetime.timedelta(hours=24)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "#             max_results = str(200)\n",
    "#             sort_type = 'FIRST_TO_START'\n",
    "#             metadata = '[\"EVENT_TYPE\", \"COMPETITION\", \"EVENT\", \"MARKET_START_TIME\", \"MARKET_DESCRIPTION\", \"RUNNER_DESCRIPTION\"]' #, \"RUNNER_METADATA\"]'\n",
    "#             inplay = 'false'\n",
    "\n",
    "#             user_req='{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/listMarketCatalogue\",\\\n",
    "#                        \"params\": {\"filter\":{\"eventTypeIds\":'+event_type_id+',\"marketTypeCodes\":'+market_types+',\\\n",
    "#                        \"inPlayOnly\":'+inplay+', \"eventIds\":'+match_event_id+',  \\\n",
    "#                        \"marketStartTime\":{\"from\":\"'+market_start_time+'\", \"to\":\"'+market_end_time+'\"}},\\\n",
    "#                        \"sort\":\"'+sort_type+'\", \"maxResults\":\"'+max_results+'\", \"marketProjection\":'+metadata+'}, \"id\": 1}'\n",
    "\n",
    "#             request = requests.post(bet_url, data=user_req.encode('utf-8'), headers=headers, timeout=30)\n",
    "#             market_catalogue += request.json()['result']\n",
    "\n",
    "        logging.info('Markets retrieved ')\n",
    "        \n",
    "        market_info_time_utc = datetime.datetime.utcnow()\n",
    "        print(f'Markets retrieved at {str(market_info_time_utc)} UTC, time taken: {round(end_time - start_time, 2)}s')\n",
    "        \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Error getting markets, trying again in one minute: '+str(error))\n",
    "        logging.error('Error getting markets, error: '+str(error))\n",
    "        time.sleep(60)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    # PARSE MARKET DETAILS\n",
    "    try:\n",
    "        market_definitions = []\n",
    "        runners = []\n",
    "        for m in market_catalogue:\n",
    "            market_definitions.append(parse_market_details(m))\n",
    "            runners += parse_runners(m)\n",
    "\n",
    "        market_definitions_df = pd.DataFrame(market_definitions, columns=md_cols)\n",
    "        market_definitions_df['api_call_time_utc'] = market_info_time_utc\n",
    "        runners_df = pd.DataFrame(runners, columns=r_cols)\n",
    "        runners_df['api_call_time_utc'] = market_info_time_utc\n",
    "        \n",
    "        # add time to event\n",
    "        market_definitions_df['minutes_to_event'] = (\n",
    "            (pd.to_datetime(market_definitions_df['market_time']) - pd.to_datetime(market_definitions_df['api_call_time_utc'], utc=True)).dt.days*24*60 +\n",
    "            (pd.to_datetime(market_definitions_df['market_time']) - pd.to_datetime(market_definitions_df['api_call_time_utc'], utc=True)).dt.seconds/60)\n",
    "        \n",
    "        logging.info(f'Parsed {len(market_definitions_df)} markets')\n",
    "        print(f'Parsed {len(market_definitions_df)} markets')\n",
    "        \n",
    "        # subset to only events that have all markets (this is a little loose but seems to work ok)\n",
    "        event_markets = market_definitions_df.groupby(['event_id', 'market_type']).head(1).groupby('event_id').size().reset_index().rename(columns={0: 'number_markets'})\n",
    "        event_markets_complete = event_markets[event_markets['number_markets']>=7]\n",
    "        market_definitions_df = market_definitions_df[market_definitions_df['event_id'].isin(event_markets_complete['event_id'])]\n",
    "        runners_df = runners_df[runners_df['market_id'].isin(market_definitions_df['market_id'])]\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        logging.error('Error parsing markets')\n",
    "        print('Error parsing markets, trying again in one minute: '+str(error))\n",
    "        \n",
    "        time.sleep(60)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    # GET ODDS\n",
    "    try:\n",
    "        print('Getting odds')\n",
    "        markets = list(market_definitions_df['market_id'].unique())\n",
    "        start_time = time.time()\n",
    "        def get_market_odds(market_id):\n",
    "            priceProjection = '[\"EX_BEST_OFFERS\"]'\n",
    "            prices_req = '{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/listMarketBook\", \"params\": {\"marketIds\": [\"' + market_id + '\"],\"priceProjection\":{\"priceData\":[\"EX_BEST_OFFERS\"]}}, \"id\": 1}'\n",
    "            request = requests.post(bet_url, data=prices_req.encode('utf-8'), headers=headers, timeout=30)\n",
    "            prices_result = request.json()\n",
    "\n",
    "            return prices_result['result'][0]\n",
    "\n",
    "        p = Pool(4)\n",
    "        market_books_mp = p.imap(get_market_odds, markets)\n",
    "        p.close()\n",
    "        p.join() # this ensures imap has finished before moving on\n",
    "        market_books = [m for m in market_books_mp]\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f'Time taken: {round(end_time - start_time, 2)}s')\n",
    "        \n",
    "#         market_books = []\n",
    "#         for m in tqdm_notebook(markets):\n",
    "\n",
    "#             priceProjection = '[\"EX_BEST_OFFERS\"]'\n",
    "#             prices_req = '{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/listMarketBook\", \"params\": {\"marketIds\": [\"' + m + '\"],\"priceProjection\":{\"priceData\":[\"EX_BEST_OFFERS\"]}}, \"id\": 1}'\n",
    "#             request = requests.post(bet_url, data=prices_req.encode('utf-8'), headers=headers, timeout=30)\n",
    "#             prices_result = request.json()\n",
    "\n",
    "#             market_books.append(prices_result['result'][0])\n",
    "            \n",
    "        market_books_lists = []\n",
    "        market_odds_lists = []\n",
    "        for m in market_books:\n",
    "            market_books_lists.append(parse_market_book(m))\n",
    "            market_odds_lists += parse_market_odds(m)    \n",
    "        \n",
    "        market_books_df = pd.DataFrame(market_books_lists, columns=mb_cols)\n",
    "        market_odds_df = pd.DataFrame(market_odds_lists, columns=odds_cols)\n",
    "        \n",
    "        logging.info('Odds retrieved')\n",
    "        print(f'Odds retrieved, time taken: {round(end_time - start_time, 2)}s')\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        logging.error('Error getting and parsing odds: '+str(error))\n",
    "        print('Error getting and parsing odds, trying again in one minute: '+str(error))\n",
    "        time.sleep(60)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    # RESHAPE TO PREDICTION DATA\n",
    "    \n",
    "    # combine market info\n",
    "    md_len_check = len(market_definitions_df)\n",
    "    mb_len_check = len(market_definitions_df)\n",
    "\n",
    "    market_details_combined = market_definitions_df[market_definition_columns].merge(market_books_df[market_book_columns], how='left', on='market_id')\n",
    "\n",
    "    if md_len_check!=len(market_details_combined):\n",
    "        raise StopIteration('Duplicate markets!')\n",
    "\n",
    "    if mb_len_check!=len(market_details_combined):\n",
    "        raise StopIteration('Potentially missing some market details!')\n",
    "        \n",
    "    # combine runners and odds\n",
    "    runner_len_check = len(runners_df)\n",
    "    odds_len_check = len(market_odds_df)\n",
    "\n",
    "    runners_and_odds = runners_df[runner_cols].merge(market_odds_df[market_odds_cols], how='left', on=['runner_id', 'market_id'])\n",
    "\n",
    "    if runner_len_check!=len(runners_and_odds):\n",
    "        raise StopIteration('Duplicate runners!')\n",
    "\n",
    "    if odds_len_check!=len(runners_and_odds):\n",
    "        raise StopIteration('Potentially missing runner or odds details!')\n",
    "    \n",
    "    combined_data = market_details_combined.merge(runners_and_odds.drop(columns='api_call_time_utc'), how='left', on='market_id', suffixes=('_market', '_runner'))\n",
    "    \n",
    "    # change to generic home/away names\n",
    "    home_mask = [str(r)==str(n)[:len(r)] for r, n in zip(combined_data['runner_name'], combined_data['event_name'])]\n",
    "    away_mask = [str(r)==str(n)[-len(r):] for r, n in zip(combined_data['runner_name'], combined_data['event_name'])]\n",
    "    combined_data['runner_name_general'] = combined_data['runner_name']\n",
    "    combined_data.loc[home_mask, 'runner_name_general'] = 'Home'\n",
    "    combined_data.loc[away_mask, 'runner_name_general'] = 'Away'\n",
    "\n",
    "    combined_data['market_runner'] = combined_data['market_type'] + ' ' + combined_data['runner_name_general']\n",
    "    \n",
    "    # create per event data\n",
    "    per_event_data = combined_data.pivot_table(\n",
    "        values=['back_price_1', 'market_id', 'runner_id', 'runner_name'], index=['event_id', 'event_name'], columns='market_runner', aggfunc=max, fill_value=None)\n",
    "    per_event_data.columns = [c[1]+' - '+c[0] for c in per_event_data.columns]\n",
    "    per_event_data.columns = [c.replace('back_price_1', 'ltp') for c in per_event_data.columns]\n",
    "    per_event_data = per_event_data.reset_index()\n",
    "\n",
    "    # check all markets exist and subset data to only complete events\n",
    "    per_event_data_complete = per_event_data[per_event_data[select_markets].isnull().sum(axis=1)==0]\n",
    "    pred_df = per_event_data_complete.copy()\n",
    "    minutes_to_event_min = combined_data.groupby('event_id')['minutes_to_event'].min().reset_index()\n",
    "    pred_df = pred_df.merge(minutes_to_event_min, how='left', on='event_id')\n",
    "    \n",
    "    print(f'Prediction data created for {len(pred_df)} events')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # DO PREDS\n",
    "    for o in select_markets:\n",
    "        outcome = o.replace(' - ltp', ' - win')\n",
    "        pred_col = o.replace(' - ltp', ' - pred')\n",
    "        pred_odds_col = pred_col+'_odds'\n",
    "        model = football_models[outcome]['model']\n",
    "        features = football_models[outcome]['features']\n",
    "\n",
    "        pred_X = pred_df[features]\n",
    "        pred_X.insert(loc=0, column='const', value=1)\n",
    "\n",
    "        pred_df[pred_col] = model.predict(pred_X)\n",
    "        #print(o+' first pred: '+str(pred_df[pred_col].iloc[0]))\n",
    "        pred_df[pred_odds_col] = 1/pred_df[pred_col]    \n",
    "    print('Predictions done')\n",
    "    logging.info('Predictions done')\n",
    "    \n",
    "    \n",
    "    for o in select_markets: # NOTE: in pred_df the 'ltp' prices are actually the back price 1 prices\n",
    "        # SELECTING BETS CARRIED OUT LATER ON (STILL INSERTING COLUMN HERE TO RETAIN FIELD FOR SENDING TO DB)\n",
    "#         outcome = o.replace(' - ltp', ' - win')\n",
    "#         pred_col = o.replace(' - ltp', ' - pred')\n",
    "#         pred_odds_col = pred_col+'_odds'\n",
    "        bet_col = o.replace(' - ltp', ' - bet')\n",
    "\n",
    "#        pred_df[bet_col] = ((pred_df[o]>pred_df[pred_odds_col]*odds_margin_mult) & (pred_df[o].between(min_odds, max_odds)))*1\n",
    "        pred_df[bet_col] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # FIND OVERROUNDS\n",
    "    for o in select_markets:\n",
    "        pred_df[o.replace(' - ltp', ' - bookie_probs')] = 1/pred_df[o]\n",
    "\n",
    "    bookie_prob_cols = [c for c in pred_df.columns if 'bookie_probs' in c]\n",
    "    correct_score_prob_cols = [c for c in bookie_prob_cols if 'CORRECT_SCORE' in c]\n",
    "    match_odds_prob_cols = [c for c in bookie_prob_cols if 'MATCH_ODDS' in c]\n",
    "    over_under_prob_cols = [c for c in bookie_prob_cols if 'OVER_UNDER' in c]\n",
    "    pred_df['correct_score_overround'] = pred_df[correct_score_prob_cols].sum(axis=1)\n",
    "    pred_df['match_odds_overround'] = pred_df[match_odds_prob_cols].sum(axis=1)\n",
    "    pred_df['over_under_overround'] = pred_df[over_under_prob_cols].sum(axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # MELT DATA BACK TO LONG FORM\n",
    "    pred_df_long = []\n",
    "    for o in select_markets:\n",
    "        market_runner = o.replace(' - ltp', '')\n",
    "        market_id_col = o.replace(' - ltp', ' - market_id')\n",
    "        pred_col = o.replace(' - ltp', ' - pred')\n",
    "        pred_odds_col = o.replace(' - ltp', ' - pred_odds')\n",
    "        bets_col = o.replace(' - ltp', ' - bet')\n",
    "\n",
    "        tmp_df = pred_df[[o, market_id_col, pred_col, pred_odds_col, bets_col, 'correct_score_overround', 'match_odds_overround', 'over_under_overround']]\n",
    "        tmp_df.columns = ['input_odds', 'market_id', 'pred', 'pred_odds', 'bet', 'correct_score_overround', 'match_odds_overround', 'over_under_overround']\n",
    "        tmp_df['market_runner'] = market_runner\n",
    "        pred_df_long.append(tmp_df)\n",
    "\n",
    "    pred_df_long = pd.concat(pred_df_long, axis=0)\n",
    "    output_df = combined_data.merge(pred_df_long, how='left', on=['market_id', 'market_runner'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ADD BASE BETTING CONSTRAINTS\n",
    "    odds_margin_mult = 1.25\n",
    "    odds_margin_mult_cs = 1.25\n",
    "    min_odds = 0\n",
    "    max_odds = 30\n",
    "    max_overround_cs = 1.03\n",
    "    max_overround_mo = 1.05\n",
    "    max_mins_to_event = 600\n",
    "\n",
    "    exclude_uncertain_cs = ~((output_df['lay_price_1'] - output_df['back_price_1'])/output_df['back_price_1'] <= 0.1) & (output_df['market_type'] == 'CORRECT_SCORE')\n",
    "\n",
    "    output_df['bet'] = (\n",
    "        (output_df['back_price_1']>=output_df['pred_odds']*odds_margin_mult) &\n",
    "        ~((output_df['back_price_1']<output_df['pred_odds']*odds_margin_mult_cs) & (output_df['market_type']=='CORRECT_SCORE')) &\n",
    "        (output_df['back_price_1'].between(min_odds, max_odds)) &\n",
    "        (output_df['correct_score_overround']<=max_overround_cs) & \n",
    "        (output_df['match_odds_overround']<=max_overround_mo) &\n",
    "        (output_df['minutes_to_event']<=max_mins_to_event) &\n",
    "        (output_df['market_type']!='OVER_UNDER_05') &\n",
    "        ~((output_df['market_id'].astype(str)+output_df['runner_id'].astype(str)).isin((existing_back_bets['market_id'].astype(str)+existing_back_bets['runner_id'].astype(str)))) &\n",
    "        ~exclude_uncertain_cs\n",
    "    )*1\n",
    "    \n",
    "    total_bets = sum(output_df[\"bet\"])\n",
    "    print(f'Found {total_bets} back bets')\n",
    "    logging.info(f'Found {total_bets} back bets')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # PLACE BASE BETS\n",
    "    order_results = []\n",
    "    order_fails = []\n",
    "    \n",
    "    back_bets = output_df[output_df['bet']==1]\n",
    "    \n",
    "    max_bet = 2\n",
    "\n",
    "    # back bets\n",
    "    for i in back_bets.index:\n",
    "        market_id = str(back_bets.at[i, 'market_id'])\n",
    "        selection_id = str(back_bets.at[i, 'runner_id'])\n",
    "        available = back_bets.at[i, 'back_size_1']\n",
    "        bet_size = str(min(available, max_bet))\n",
    "        price = str(back_bets.at[i, 'back_price_1'])\n",
    "        min_fill_size = str(2)\n",
    "        market_version = str(back_bets.at[i, 'version'])\n",
    "\n",
    "        try:\n",
    "            order_request = '{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/placeOrders\",\\\n",
    "                        \"params\": {\"marketId\":\"' + market_id + '\",\"instructions\":[\\\n",
    "                        {\"selectionId\":\"' + selection_id + '\",\"handicap\":\"0\",\"side\":\"BACK\",\"orderType\":\"LIMIT\",\\\n",
    "                        \"limitOrder\":{\"size\":\"' + bet_size + '\",\"price\":\"' + price + '\",\"persistenceType\":\"LAPSE\",\\\n",
    "                        \"timeInForce\":\"FILL_OR_KILL\", \"minFillSize\":\"' + min_fill_size + '\"}}], \"marketVersion\":{\"version\":\"' + market_version + '\"}}, \"id\": 1}'\n",
    "            request = requests.post(bet_url, data=order_request.encode('utf-8'), headers=headers, timeout=30)\n",
    "            order_result = request.json()['result']\n",
    "            order_results.append(order_result)\n",
    "        except:\n",
    "            order_fails.append([market_id, selection_id, available, bet_size, price, min_fill_size, market_version])\n",
    "        \n",
    "    if len(back_bets)>0:\n",
    "        print('Bets placed!')\n",
    "        logging.info('Bets placed!')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ADD SECONDARY STRATEGY BETS\n",
    "    \n",
    "    # unpack artifacts\n",
    "    model_sl = football_models_secondary_layer['model']\n",
    "    features_sl = football_models_secondary_layer['features']\n",
    "    rc_features_sl = football_models_secondary_layer['rc_features']\n",
    "    rc_dict_sl = football_models_secondary_layer['response_codes']\n",
    "    \n",
    "    output_df_secondary = output_df.copy()\n",
    "    for c in rc_features_sl:\n",
    "        response_codes_df = rc_dict_sl[c]\n",
    "        output_df_secondary = output_df_secondary.merge(response_codes_df, how='left', on=c)\n",
    "        \n",
    "    output_df_secondary = output_df_secondary[output_df_secondary[features_sl].isnull().sum(axis=1)==0]\n",
    "    pred_sl_df = xgb.DMatrix(output_df_secondary[features_sl])\n",
    "    output_df_secondary['pred_secondary_layer'] = model_sl.predict(pred_sl_df)\n",
    "    \n",
    "    # constraints\n",
    "    bet_cutoff = 0.25\n",
    "    odds_max = 20\n",
    "    competition_name_rc_count_min = 10\n",
    "    \n",
    "    output_df_secondary['bet_secondary_layer'] = (\n",
    "        (output_df_secondary['bet'] == 1) &  # EVENTUALLY RE DO THIS TO DO ITS OWN CHECK, AND CHECK SECOND LAYER OUTSTANDING AMOUNT TO BET SEPARATELY\n",
    "        (output_df_secondary['pred_secondary_layer'] > bet_cutoff) &\n",
    "        (output_df_secondary['back_price_1'] <= odds_max) &\n",
    "        (output_df_secondary['competition_name_count'] >= competition_name_rc_count_min)\n",
    "    )*1\n",
    "    \n",
    "    total_bets_sl = sum(output_df_secondary[\"bet_secondary_layer\"])\n",
    "    print(f'Found {total_bets_sl} secondary layer bets')\n",
    "    logging.info(f'Found {total_bets_sl} secondary layer bets')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # PLACE SECONDARY STRATEGY BETS\n",
    "    order_results_sl = []\n",
    "    order_fails_sl = []\n",
    "    \n",
    "    back_bets_sl = output_df_secondary[output_df_secondary['bet_secondary_layer']==1]\n",
    "    \n",
    "    max_bet_sl = 2\n",
    "\n",
    "    # back bets\n",
    "    # TO DO:\n",
    "    # - ADD IN NEW BASE LAYER BET CHECK WITHOUT CHECKING WHETHER BET ALREADY MEETS max_bet, TO ALLOW FOR RAMPING UP OF BET SIZES OVER TIME\n",
    "    # - PICK UP AMOUNT ALREADY BET FOR EACH SELECTION AS PART OF SECONDARY LAYER\n",
    "    # - CHECK THAT bet_id IS DIFFERENT FOR SECONDARY BETS\n",
    "    \n",
    "    for i in back_bets_sl.index:\n",
    "        market_id = str(back_bets_sl.at[i, 'market_id'])\n",
    "        selection_id = str(back_bets_sl.at[i, 'runner_id'])\n",
    "        already_bet_since_data_extracted = (back_bets_sl.at[i, 'bet']==1)*max_bet\n",
    "        available = back_bets_sl.at[i, 'back_size_1'] - already_bet_since_data_extracted\n",
    "        bet_size = str(min(available, max_bet_sl))\n",
    "        price = str(back_bets_sl.at[i, 'back_price_1'])\n",
    "        min_fill_size = str(2)\n",
    "        market_version = str(back_bets_sl.at[i, 'version'])\n",
    "\n",
    "        try:\n",
    "            # FROM API DOCS:\n",
    "            # FILL_OR_KILL: Execute the transaction immediately and completely (filled to size or between minFillSize and size) or not at all (cancelled).\n",
    "            # May want to consider removing FILL_OR_KILL in future to allow more time for bets to be matched\n",
    "            order_request = '{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/placeOrders\",\\\n",
    "                        \"params\": {\"marketId\":\"' + market_id + '\",\"instructions\":[\\\n",
    "                        {\"selectionId\":\"' + selection_id + '\",\"handicap\":\"0\",\"side\":\"BACK\",\"orderType\":\"LIMIT\",\\\n",
    "                        \"limitOrder\":{\"size\":\"' + bet_size + '\",\"price\":\"' + price + '\",\"persistenceType\":\"LAPSE\",\\\n",
    "                        \"timeInForce\":\"FILL_OR_KILL\", \"minFillSize\":\"' + min_fill_size + '\"}}], \"marketVersion\":{\"version\":\"' + market_version + '\"}}, \"id\": 1}'\n",
    "            request = requests.post(bet_url, data=order_request.encode('utf-8'), headers=headers, timeout=30)\n",
    "            order_result = request.json()['result']\n",
    "            order_results_sl.append(order_result)\n",
    "        except:\n",
    "            order_fails_sl.append([market_id, selection_id, available, bet_size, price, min_fill_size, market_version])\n",
    "        \n",
    "    if len(back_bets_sl)>0:\n",
    "        print('Bets placed!')\n",
    "        logging.info('Bets placed!')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # GET RESULTS AND SEND DATA TO DB\n",
    "    order_results_df = []\n",
    "    for o in order_results:\n",
    "        order_results_df.append(parse_order_result(o))\n",
    "    order_results_df = pd.DataFrame(order_results_df, columns=order_cols)\n",
    "    \n",
    "    order_results_sl_df = []\n",
    "    for o in order_results_sl:\n",
    "        order_results_sl_df.append(parse_order_result(o))\n",
    "    order_results_sl_df = pd.DataFrame(order_results_sl_df, columns=order_cols)\n",
    "\n",
    "    order_fails_df = pd.DataFrame(order_fails, columns=['market_id', 'selection_id', 'available', 'bet_size', 'price', 'min_fill_size', 'market_version'])\n",
    "    \n",
    "    order_fails_sl_df = pd.DataFrame(order_fails_sl, columns=['market_id', 'selection_id', 'available', 'bet_size', 'price', 'min_fill_size', 'market_version'])\n",
    "        \n",
    "    connect_string = 'mysql+pymysql://root:'+dbpw+'@localhost/betfair'\n",
    "    sql_engine = sqlalchemy.create_engine(connect_string)\n",
    "    \n",
    "    # drop pred bet cols in case confusing later on\n",
    "    pred_df = pred_df.drop(columns=[o.replace(' - ltp', ' - bet') for o in select_markets])\n",
    "    \n",
    "    pred_df[pred_df_output_cols].to_sql(name='football_predictions_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "    output_df.to_sql(name='football_output_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "    order_results_df.to_sql(name='football_order_results_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "    order_fails_df.to_sql(name='football_order_fails_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "    \n",
    "    output_df_secondary.to_sql(name='football_output_secondary_layer_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "    order_results_sl_df.to_sql(name='football_order_results_secondary_layer_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "    order_fails_sl_df.to_sql(name='football_order_fails_secondary_layer_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "    \n",
    "    print('Data sent to DB')\n",
    "    logging.info('Data sent to DB')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # SLEEP AND REPEAT\n",
    "    end_time = time.time()\n",
    "    print(f'Total time taken: {round(end_time - start_time, 3)} seconds')\n",
    "    retry_counter = 0\n",
    "    time.sleep(30*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing secondary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD SECONDARY STRATEGY BETS\n",
    "\n",
    "# unpack artifacts\n",
    "model_sl = football_models_secondary_layer['model']\n",
    "features_sl = football_models_secondary_layer['features']\n",
    "rc_features_sl = football_models_secondary_layer['rc_features']\n",
    "rc_dict_sl = football_models_secondary_layer['response_codes']\n",
    "\n",
    "output_df_secondary = output_df.copy()\n",
    "for c in rc_features_sl:\n",
    "    response_codes_df = rc_dict_sl[c]\n",
    "    output_df_secondary = output_df_secondary.merge(response_codes_df, how='left', on=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_id</th>\n",
       "      <th>market_start_time</th>\n",
       "      <th>market_time</th>\n",
       "      <th>suspend_time</th>\n",
       "      <th>open_date</th>\n",
       "      <th>api_call_time_utc</th>\n",
       "      <th>minutes_to_event</th>\n",
       "      <th>event_id</th>\n",
       "      <th>venue</th>\n",
       "      <th>event_name</th>\n",
       "      <th>competition_id</th>\n",
       "      <th>competition_name</th>\n",
       "      <th>race_type</th>\n",
       "      <th>market_name</th>\n",
       "      <th>market_type</th>\n",
       "      <th>event_type_id</th>\n",
       "      <th>betting_type</th>\n",
       "      <th>country_code</th>\n",
       "      <th>timezone</th>\n",
       "      <th>bsp_market</th>\n",
       "      <th>in_play_enabled</th>\n",
       "      <th>persistence_enabled</th>\n",
       "      <th>market_base_rate</th>\n",
       "      <th>regulator</th>\n",
       "      <th>discount_allowed</th>\n",
       "      <th>number_of_winners</th>\n",
       "      <th>number_of_runners</th>\n",
       "      <th>number_of_active_runners</th>\n",
       "      <th>last_match_time</th>\n",
       "      <th>total_matched_market</th>\n",
       "      <th>total_available</th>\n",
       "      <th>cross_matching</th>\n",
       "      <th>runners_voidable</th>\n",
       "      <th>version</th>\n",
       "      <th>is_market_data_delayed</th>\n",
       "      <th>market_status</th>\n",
       "      <th>bet_delay</th>\n",
       "      <th>bsp_reconciled</th>\n",
       "      <th>complete</th>\n",
       "      <th>inplay</th>\n",
       "      <th>runner_id</th>\n",
       "      <th>runner_name</th>\n",
       "      <th>sort_priority</th>\n",
       "      <th>handicap</th>\n",
       "      <th>status</th>\n",
       "      <th>ltp</th>\n",
       "      <th>total_matched_runner</th>\n",
       "      <th>back_price_1</th>\n",
       "      <th>back_price_2</th>\n",
       "      <th>back_price_3</th>\n",
       "      <th>back_size_1</th>\n",
       "      <th>back_size_2</th>\n",
       "      <th>back_size_3</th>\n",
       "      <th>lay_price_1</th>\n",
       "      <th>lay_price_2</th>\n",
       "      <th>lay_price_3</th>\n",
       "      <th>lay_size_1</th>\n",
       "      <th>lay_size_2</th>\n",
       "      <th>lay_size_3</th>\n",
       "      <th>runner_name_general</th>\n",
       "      <th>market_runner</th>\n",
       "      <th>input_odds</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_odds</th>\n",
       "      <th>bet</th>\n",
       "      <th>correct_score_overround</th>\n",
       "      <th>match_odds_overround</th>\n",
       "      <th>over_under_overround</th>\n",
       "      <th>runner_name_general_count</th>\n",
       "      <th>runner_name_general_rc</th>\n",
       "      <th>competition_name_count</th>\n",
       "      <th>competition_name_rc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.192810767</td>\n",
       "      <td>2022-01-15T18:00:00.000Z</td>\n",
       "      <td>2022-01-15T18:00:00.000Z</td>\n",
       "      <td>2022-01-15T18:00:00.000Z</td>\n",
       "      <td>2022-01-15T18:00:00.000Z</td>\n",
       "      <td>2022-01-15 11:26:23.910982</td>\n",
       "      <td>393.6</td>\n",
       "      <td>31147933</td>\n",
       "      <td>None</td>\n",
       "      <td>Toulouse v Pau</td>\n",
       "      <td>57</td>\n",
       "      <td>French Ligue 2</td>\n",
       "      <td>None</td>\n",
       "      <td>Correct Score</td>\n",
       "      <td>CORRECT_SCORE</td>\n",
       "      <td>1</td>\n",
       "      <td>ODDS</td>\n",
       "      <td>FR</td>\n",
       "      <td>GMT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GIBRALTAR REGULATOR</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>2022-01-15T11:21:19.118Z</td>\n",
       "      <td>15.73</td>\n",
       "      <td>11196.04</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4287336187</td>\n",
       "      <td>True</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0 - 0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.08</td>\n",
       "      <td>19.63</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 - 0</td>\n",
       "      <td>CORRECT_SCORE 0 - 0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.073207</td>\n",
       "      <td>13.659957</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018141</td>\n",
       "      <td>1.020303</td>\n",
       "      <td>5.234038</td>\n",
       "      <td>417.0</td>\n",
       "      <td>-0.094484</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-0.854545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.192810767</td>\n",
       "      <td>2022-01-15T18:00:00.000Z</td>\n",
       "      <td>2022-01-15T18:00:00.000Z</td>\n",
       "      <td>2022-01-15T18:00:00.000Z</td>\n",
       "      <td>2022-01-15T18:00:00.000Z</td>\n",
       "      <td>2022-01-15 11:26:23.910982</td>\n",
       "      <td>393.6</td>\n",
       "      <td>31147933</td>\n",
       "      <td>None</td>\n",
       "      <td>Toulouse v Pau</td>\n",
       "      <td>57</td>\n",
       "      <td>French Ligue 2</td>\n",
       "      <td>None</td>\n",
       "      <td>Correct Score</td>\n",
       "      <td>CORRECT_SCORE</td>\n",
       "      <td>1</td>\n",
       "      <td>ODDS</td>\n",
       "      <td>FR</td>\n",
       "      <td>GMT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GIBRALTAR REGULATOR</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>2022-01-15T11:21:19.118Z</td>\n",
       "      <td>15.73</td>\n",
       "      <td>11196.04</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4287336187</td>\n",
       "      <td>True</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>10.80</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.89</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>CORRECT_SCORE 0 - 1</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.036480</td>\n",
       "      <td>27.411969</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018141</td>\n",
       "      <td>1.020303</td>\n",
       "      <td>5.234038</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.096087</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-0.854545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.192810767</td>\n",
       "      <td>2022-01-15T18:00:00.000Z</td>\n",
       "      <td>2022-01-15T18:00:00.000Z</td>\n",
       "      <td>2022-01-15T18:00:00.000Z</td>\n",
       "      <td>2022-01-15T18:00:00.000Z</td>\n",
       "      <td>2022-01-15 11:26:23.910982</td>\n",
       "      <td>393.6</td>\n",
       "      <td>31147933</td>\n",
       "      <td>None</td>\n",
       "      <td>Toulouse v Pau</td>\n",
       "      <td>57</td>\n",
       "      <td>French Ligue 2</td>\n",
       "      <td>None</td>\n",
       "      <td>Correct Score</td>\n",
       "      <td>CORRECT_SCORE</td>\n",
       "      <td>1</td>\n",
       "      <td>ODDS</td>\n",
       "      <td>FR</td>\n",
       "      <td>GMT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GIBRALTAR REGULATOR</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>2022-01-15T11:21:19.118Z</td>\n",
       "      <td>15.73</td>\n",
       "      <td>11196.04</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4287336187</td>\n",
       "      <td>True</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0 - 2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.26</td>\n",
       "      <td>10.00</td>\n",
       "      <td>122.16</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 - 2</td>\n",
       "      <td>CORRECT_SCORE 0 - 2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.023740</td>\n",
       "      <td>42.123483</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018141</td>\n",
       "      <td>1.020303</td>\n",
       "      <td>5.234038</td>\n",
       "      <td>197.0</td>\n",
       "      <td>-0.745178</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-0.854545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     market_id         market_start_time               market_time  \\\n",
       "0  1.192810767  2022-01-15T18:00:00.000Z  2022-01-15T18:00:00.000Z   \n",
       "1  1.192810767  2022-01-15T18:00:00.000Z  2022-01-15T18:00:00.000Z   \n",
       "2  1.192810767  2022-01-15T18:00:00.000Z  2022-01-15T18:00:00.000Z   \n",
       "\n",
       "               suspend_time                 open_date  \\\n",
       "0  2022-01-15T18:00:00.000Z  2022-01-15T18:00:00.000Z   \n",
       "1  2022-01-15T18:00:00.000Z  2022-01-15T18:00:00.000Z   \n",
       "2  2022-01-15T18:00:00.000Z  2022-01-15T18:00:00.000Z   \n",
       "\n",
       "           api_call_time_utc  minutes_to_event  event_id venue  \\\n",
       "0 2022-01-15 11:26:23.910982             393.6  31147933  None   \n",
       "1 2022-01-15 11:26:23.910982             393.6  31147933  None   \n",
       "2 2022-01-15 11:26:23.910982             393.6  31147933  None   \n",
       "\n",
       "       event_name competition_id competition_name race_type    market_name  \\\n",
       "0  Toulouse v Pau             57   French Ligue 2      None  Correct Score   \n",
       "1  Toulouse v Pau             57   French Ligue 2      None  Correct Score   \n",
       "2  Toulouse v Pau             57   French Ligue 2      None  Correct Score   \n",
       "\n",
       "     market_type event_type_id betting_type country_code timezone  bsp_market  \\\n",
       "0  CORRECT_SCORE             1         ODDS           FR      GMT       False   \n",
       "1  CORRECT_SCORE             1         ODDS           FR      GMT       False   \n",
       "2  CORRECT_SCORE             1         ODDS           FR      GMT       False   \n",
       "\n",
       "   in_play_enabled  persistence_enabled  market_base_rate  \\\n",
       "0             True                 True               2.0   \n",
       "1             True                 True               2.0   \n",
       "2             True                 True               2.0   \n",
       "\n",
       "             regulator  discount_allowed  number_of_winners  \\\n",
       "0  GIBRALTAR REGULATOR             False                  1   \n",
       "1  GIBRALTAR REGULATOR             False                  1   \n",
       "2  GIBRALTAR REGULATOR             False                  1   \n",
       "\n",
       "   number_of_runners  number_of_active_runners           last_match_time  \\\n",
       "0                 19                        19  2022-01-15T11:21:19.118Z   \n",
       "1                 19                        19  2022-01-15T11:21:19.118Z   \n",
       "2                 19                        19  2022-01-15T11:21:19.118Z   \n",
       "\n",
       "   total_matched_market  total_available  cross_matching  runners_voidable  \\\n",
       "0                 15.73         11196.04            True             False   \n",
       "1                 15.73         11196.04            True             False   \n",
       "2                 15.73         11196.04            True             False   \n",
       "\n",
       "      version  is_market_data_delayed market_status  bet_delay  \\\n",
       "0  4287336187                    True          OPEN          0   \n",
       "1  4287336187                    True          OPEN          0   \n",
       "2  4287336187                    True          OPEN          0   \n",
       "\n",
       "   bsp_reconciled  complete  inplay  runner_id runner_name  sort_priority  \\\n",
       "0           False      True   False          1       0 - 0              1   \n",
       "1           False      True   False          4       0 - 1              2   \n",
       "2           False      True   False          9       0 - 2              3   \n",
       "\n",
       "   handicap  status  ltp  total_matched_runner  back_price_1  back_price_2  \\\n",
       "0       0.0  ACTIVE  NaN                   0.0          13.0          11.5   \n",
       "1       0.0  ACTIVE  NaN                   0.0          19.5          19.0   \n",
       "2       0.0  ACTIVE  NaN                   0.0          42.0          32.0   \n",
       "\n",
       "   back_price_3  back_size_1  back_size_2  back_size_3  lay_price_1  \\\n",
       "0           9.6        16.67        16.08        19.63         18.0   \n",
       "1          16.5        10.80        10.00        10.89         27.0   \n",
       "2           6.0        14.26        10.00       122.16         70.0   \n",
       "\n",
       "   lay_price_2  lay_price_3  lay_size_1  lay_size_2  lay_size_3  \\\n",
       "0          NaN          NaN       45.64         NaN         NaN   \n",
       "1          NaN          NaN       33.78         NaN         NaN   \n",
       "2          NaN          NaN       14.79         NaN         NaN   \n",
       "\n",
       "  runner_name_general        market_runner  input_odds      pred  pred_odds  \\\n",
       "0               0 - 0  CORRECT_SCORE 0 - 0        13.0  0.073207  13.659957   \n",
       "1               0 - 1  CORRECT_SCORE 0 - 1        19.5  0.036480  27.411969   \n",
       "2               0 - 2  CORRECT_SCORE 0 - 2        42.0  0.023740  42.123483   \n",
       "\n",
       "   bet  correct_score_overround  match_odds_overround  over_under_overround  \\\n",
       "0    0                 1.018141              1.020303              5.234038   \n",
       "1    0                 1.018141              1.020303              5.234038   \n",
       "2    0                 1.018141              1.020303              5.234038   \n",
       "\n",
       "   runner_name_general_count  runner_name_general_rc  competition_name_count  \\\n",
       "0                      417.0               -0.094484                    22.0   \n",
       "1                       23.0                1.096087                    22.0   \n",
       "2                      197.0               -0.745178                    22.0   \n",
       "\n",
       "   competition_name_rc  \n",
       "0            -0.854545  \n",
       "1            -0.854545  \n",
       "2            -0.854545  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df_secondary.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 secondary layer bets\n"
     ]
    }
   ],
   "source": [
    "output_df_secondary = output_df_secondary[output_df_secondary[features_sl].isnull().sum(axis=1)==0]\n",
    "pred_sl_df = xgb.DMatrix(output_df_secondary[features_sl])\n",
    "output_df_secondary['pred_secondary_layer'] = model_sl.predict(pred_sl_df)\n",
    "\n",
    "# constraints\n",
    "bet_cutoff = 0.25\n",
    "odds_max = 20\n",
    "competition_name_rc_count_min = 10\n",
    "\n",
    "output_df_secondary['bet_secondary_layer'] = (\n",
    "    (output_df_secondary['bet'] == 1) &  # EVENTUALLY RE DO THIS TO DO ITS OWN CHECK, AND CHECK SECOND LAYER OUTSTANDING AVAILABILITY SEPARATELY\n",
    "    (output_df_secondary['pred_secondary_layer'] > bet_cutoff) &\n",
    "    (output_df_secondary['back_price_1'] <= odds_max) &\n",
    "    (output_df_secondary['competition_name_count'] >= competition_name_rc_count_min)\n",
    ")*1\n",
    "\n",
    "total_bets_sl = sum(output_df_secondary[\"bet_secondary_layer\"])\n",
    "print(f'Found {total_bets_sl} secondary layer bets')\n",
    "logging.info(f'Found {total_bets_sl} secondary layer bets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bets placed!\n"
     ]
    }
   ],
   "source": [
    "# PLACE SECONDARY STRATEGY BETS\n",
    "order_results_sl = []\n",
    "order_fails_sl = []\n",
    "\n",
    "back_bets_sl = output_df_secondary[output_df_secondary['bet_secondary_layer']==1]\n",
    "\n",
    "max_bet_sl = 2\n",
    "\n",
    "# back bets\n",
    "# TO DO:\n",
    "# - ADD IN NEW BASE LAYER BET CHECK WITHOUT CHECKING WHETHER BET ALREADY MEETS max_bet, TO ALLOW FOR RAMPING UP OF BET SIZES OVER TIME\n",
    "# - PICK UP AMOUNT ALREADY BET FOR EACH SELECTION AS PART OF SECONDARY LAYER\n",
    "# - CHECK THAT bet_id IS DIFFERENT FOR SECONDARY BETS\n",
    "\n",
    "for i in back_bets_sl.index:\n",
    "    market_id = str(back_bets_sl.at[i, 'market_id'])\n",
    "    selection_id = str(back_bets_sl.at[i, 'runner_id'])\n",
    "    already_bet_since_data_extracted = (back_bets_sl.at[i, 'bet']==1)*max_bet\n",
    "    available = back_bets_sl.at[i, 'back_size_1'] - already_bet_since_data_extracted\n",
    "    bet_size = str(max(2, min(available, max_bet_sl)))\n",
    "    price = str(back_bets_sl.at[i, 'back_price_1'])\n",
    "    min_fill_size = str(2)\n",
    "    market_version = str(back_bets_sl.at[i, 'version'])\n",
    "\n",
    "    try:\n",
    "        # FROM API DOCS:\n",
    "        # FILL_OR_KILL: Execute the transaction immediately and completely (filled to size or between minFillSize and size) or not at all (cancelled).\n",
    "        # May want to consider removing FILL_OR_KILL in future to allow more time for bets to be matched\n",
    "        order_request = '{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/placeOrders\",\\\n",
    "                    \"params\": {\"marketId\":\"' + market_id + '\",\"instructions\":[\\\n",
    "                    {\"selectionId\":\"' + selection_id + '\",\"handicap\":\"0\",\"side\":\"BACK\",\"orderType\":\"LIMIT\",\\\n",
    "                    \"limitOrder\":{\"size\":\"' + bet_size + '\",\"price\":\"' + price + '\",\"persistenceType\":\"LAPSE\",\\\n",
    "                    \"timeInForce\":\"FILL_OR_KILL\", \"minFillSize\":\"' + min_fill_size + '\"}}], \"marketVersion\":{\"version\":\"' + market_version + '\"}}, \"id\": 1}'\n",
    "        request = requests.post(bet_url, data=order_request.encode('utf-8'), headers=headers, timeout=30)\n",
    "        order_result = request.json()['result']\n",
    "        order_results_sl.append(order_result)\n",
    "    except:\n",
    "        order_fails_sl.append([market_id, selection_id, available, bet_size, price, min_fill_size, market_version])\n",
    "\n",
    "if len(back_bets_sl)>0:\n",
    "    print('Bets placed!')\n",
    "    logging.info('Bets placed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255    124.56\n",
       "653    124.56\n",
       "Name: bet, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_results_sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_results_sl_df = []\n",
    "for o in order_results_sl:\n",
    "    order_results_sl_df.append(parse_order_result(o))\n",
    "order_results_sl_df = pd.DataFrame(order_results_sl_df, columns=order_cols)\n",
    "\n",
    "order_fails_sl_df = pd.DataFrame(order_fails_sl, columns=['market_id', 'selection_id', 'available', 'bet_size', 'price', 'min_fill_size', 'market_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_secondary.to_sql(name='football_output_secondary_layer_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "order_results_sl_df.to_sql(name='football_order_results_secondary_layer_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "order_fails_sl_df.to_sql(name='football_order_fails_secondary_layer_live', con=sql_engine, schema='betfair', if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To look at: why are predictions only done for some events - worth trying to do model with less market types to cover more events? Looked into and it is correct_score that is missing for events that are excluded, these are also the smallers games with less wagered on them. Could still try to do preds based only on match odds and over unders markets but limited potential"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
