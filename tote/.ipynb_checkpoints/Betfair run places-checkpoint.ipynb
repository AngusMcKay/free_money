{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betfair Run Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook\n",
    "import datetime\n",
    "import time\n",
    "import importlib\n",
    "import config\n",
    "importlib.reload(config)\n",
    "from config import username, password, application, dbpw\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pymysql\n",
    "import sqlalchemy\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import bf_helpers as bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='bf_places_log.log', level=logging.INFO, format='%(asctime)s, %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/angus/projects/betting/tote/models/betfair_places_model_60.pkl', 'rb') as f:\n",
    "    betfair_places_model_60 = pickle.load(f)\n",
    "\n",
    "with open('/home/angus/projects/betting/tote/models/betfair_places_model_120.pkl', 'rb') as f:\n",
    "    betfair_places_model_120 = pickle.load(f)\n",
    "    \n",
    "with open('/home/angus/projects/betting/tote/models/betfair_places_model_180.pkl', 'rb') as f:\n",
    "    betfair_places_model_180 = pickle.load(f)\n",
    "    \n",
    "with open('/home/angus/projects/betting/tote/models/betfair_places_model_240.pkl', 'rb') as f:\n",
    "    betfair_places_model_240 = pickle.load(f)\n",
    "    \n",
    "with open('/home/angus/projects/betting/tote/models/betfair_places_model_300.pkl', 'rb') as f:\n",
    "    betfair_places_model_300 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'X-Application': application, 'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "auth = 'username='+username+'&password='+password\n",
    "bet_url = \"https://api.betfair.com/exchange/betting/json-rpc/v1\"\n",
    "allow_subsequent_bets_on_same_runner = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and useful lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_places(description):\n",
    "    if description.get('marketType', '')=='WIN':\n",
    "        return 1\n",
    "    elif 'Who will finish 1st or 2nd' in description.get('rules', ''):\n",
    "        return 2\n",
    "    elif 'Who will finish 1st, 2nd or 3rd' in description.get('rules', ''):\n",
    "        return 3\n",
    "    elif 'Who will finish 1st, 2nd, 3rd or 4th' in description.get('rules', ''):\n",
    "        return 4\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "def parse_market_details(market_cat_entry):\n",
    "    \n",
    "    description = market_cat_entry.get('description', {})\n",
    "    event = market_cat_entry.get('event', {})\n",
    "    event_type = market_cat_entry.get('eventType', {})\n",
    "    \n",
    "    return [\n",
    "        market_cat_entry.get('marketId', None),\n",
    "        market_cat_entry.get('marketStartTime', None),\n",
    "        description.get('bspMarket', None),\n",
    "        description.get('turnInPlayEnabled', None),\n",
    "        description.get('persistenceEnabled', None),\n",
    "        description.get('marketBaseRate', None),\n",
    "        event.get('id', None),\n",
    "        event_type.get('id', None),\n",
    "        description.get('raceType', None),\n",
    "        parse_places(description),\n",
    "        description.get('bettingType', None),\n",
    "        description.get('marketType', None),\n",
    "        description.get('marketTime', None),\n",
    "        description.get('suspendTime', None),\n",
    "        description.get('bspReconciled', None),\n",
    "        description.get('complete', None),\n",
    "        description.get('inPlay', None),\n",
    "        str(description.get('regulator', None)),\n",
    "        event.get('venue', None),\n",
    "        event.get('countryCode', None),\n",
    "        description.get('discountAllowed', None),\n",
    "        event.get('timezone', None),\n",
    "        event.get('openDate', None),\n",
    "        event.get('name', None),\n",
    "        market_cat_entry.get('marketName', None)\n",
    "    ]\n",
    "\n",
    "\n",
    "def parse_runners(market_cat_entry):\n",
    "\n",
    "    market_id = market_cat_entry.get('marketId', None)\n",
    "    \n",
    "    runners = market_cat_entry.get('runners', {})\n",
    "    runners_list = []\n",
    "    for r in runners:\n",
    "        r_id = r.get('selectionId', None)\n",
    "        r_name = r.get('runnerName', None)\n",
    "        handicap = r.get('handicap', None)\n",
    "        sort_priority = r.get('sortPriority', None)\n",
    "        runners_list.append([r_id, r_name, handicap, sort_priority, market_id])\n",
    "    \n",
    "    return runners_list\n",
    "\n",
    "md_cols = [\n",
    "    'market_id',\n",
    "    'market_start_time',\n",
    "    'bsp_market',\n",
    "    'in_play_enabled',\n",
    "    'persistence_enabled',\n",
    "    'market_base_rate',\n",
    "    'event_id',\n",
    "    'event_type_id',\n",
    "    'race_type',\n",
    "    'number_of_winners',\n",
    "    'betting_type',\n",
    "    'market_type',\n",
    "    'market_time',\n",
    "    'suspend_time',\n",
    "    'bsp_reconciled',\n",
    "    'complete',\n",
    "    'in_play',\n",
    "    'regulator',\n",
    "    'venue',\n",
    "    'country_code',\n",
    "    'discount_allowed',\n",
    "    'timezone',\n",
    "    'open_date',\n",
    "    'event_name',\n",
    "    'market_name'\n",
    "]\n",
    "\n",
    "r_cols = ['runner_id', 'runner_name', 'handicap', 'sort_priority', 'market_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_market_book(market_book):\n",
    "    \n",
    "    return [\n",
    "        market_book.get('marketId', None),\n",
    "        market_book.get('isMarketDataDelayed', None),\n",
    "        market_book.get('status', None),\n",
    "        market_book.get('betDelay', None),\n",
    "        market_book.get('bspReconciled', None),\n",
    "        market_book.get('complete', None),\n",
    "        market_book.get('inplay', None),\n",
    "        market_book.get('numberOfWinners', None),\n",
    "        market_book.get('numberOfRunners', None),\n",
    "        market_book.get('numberOfActiveRunners', None),\n",
    "        market_book.get('lastMatchTime', None),\n",
    "        market_book.get('totalMatched', None),\n",
    "        market_book.get('totalAvailable', None),\n",
    "        market_book.get('crossMatching', None),\n",
    "        market_book.get('runnersVoidable', None),\n",
    "        market_book.get('version', None),\n",
    "        market_book.get('crossMatching', None)\n",
    "    ]\n",
    "\n",
    "def parse_market_odds(market_book):\n",
    "    \n",
    "    market_id = market_book.get('marketId', None)\n",
    "    \n",
    "    runners = market_book.get('runners', {})\n",
    "    runners_list = []\n",
    "    for r in runners:\n",
    "        r_id = r.get('selectionId', None)\n",
    "        handicap = r.get('handicap', None)\n",
    "        status = r.get('status', None)\n",
    "        sort_priority = r.get('adjustmentFactor', None)\n",
    "        ltp = r.get('lastPriceTraded', None)\n",
    "        total_matched = r.get('totalMatched', None)\n",
    "        \n",
    "        ex_back = r.get('ex', {}).get('availableToBack', [])\n",
    "        back_prices = [None, None, None]\n",
    "        back_sizes = [None, None, None]\n",
    "        for i, b in enumerate(ex_back[:3]):\n",
    "            back_prices[i] = b.get('price', None)\n",
    "            back_sizes[i] = b.get('size', None)\n",
    "        \n",
    "        ex_lay = r.get('ex', {}).get('availableToLay', [])\n",
    "        lay_prices = [None, None, None]\n",
    "        lay_sizes = [None, None, None]\n",
    "        for i, l in enumerate(ex_lay[:3]):\n",
    "            lay_prices[i] = l.get('price', None)\n",
    "            lay_sizes[i] = l.get('size', None)\n",
    "        \n",
    "        runners_list.append([r_id, handicap, status, sort_priority, ltp, total_matched] + back_prices + back_sizes + lay_prices + lay_sizes + [market_id])    \n",
    "    \n",
    "    return runners_list\n",
    "\n",
    "mb_cols = [\n",
    "    'market_id',\n",
    "    'is_market_data_delayed',\n",
    "    'market_status',\n",
    "    'bet_delay',\n",
    "    'bsp_reconciled',\n",
    "    'complete',\n",
    "    'inplay',\n",
    "    'number_of_winners',\n",
    "    'number_of_runners',\n",
    "    'number_of_active_runners',\n",
    "    'last_match_time',\n",
    "    'total_matched',\n",
    "    'total_available',\n",
    "    'cross_matching',\n",
    "    'runners_voidable',\n",
    "    'version',\n",
    "    'cross_matching'\n",
    "]\n",
    "\n",
    "mb_odds_cols = [\n",
    "    'runner_id', 'handicap', 'status', 'sort_priority', 'ltp', 'total_matched',\n",
    "    'back_price_1', 'back_price_2', 'back_price_3', 'back_size_1', 'back_size_2', 'back_size_3',\n",
    "    'lay_price_1', 'lay_price_2', 'lay_price_3', 'lay_size_1', 'lay_size_2', 'lay_size_3',\n",
    "    'market_id'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_definition_columns = [\n",
    "    'market_id', 'market_start_time', 'market_time', 'suspend_time', 'open_date', 'api_call_time_utc', 'minutes_to_event',\n",
    "    'event_id', 'venue', 'event_name', 'race_type', 'market_name', 'market_type', 'event_type_id', 'betting_type', 'country_code', 'timezone',\n",
    "    'bsp_market', 'in_play_enabled', 'persistence_enabled', 'market_base_rate', 'regulator', 'discount_allowed'\n",
    "]\n",
    "\n",
    "market_book_columns = [\n",
    "    'market_id', 'number_of_winners', 'number_of_runners', 'number_of_active_runners',\n",
    "    'last_match_time', 'total_matched', 'total_available', 'cross_matching', 'runners_voidable', 'version',\n",
    "    'cross_matching', 'is_market_data_delayed', 'market_status', 'bet_delay', 'bsp_reconciled', 'complete', 'inplay'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner_cols = [\n",
    "    'runner_id', 'runner_name', 'market_id', 'api_call_time_utc'\n",
    "]\n",
    "\n",
    "market_odds_cols = [\n",
    "    'runner_id', 'handicap', 'status', 'sort_priority', 'market_id', 'ltp', 'total_matched',\n",
    "    'back_price_1', 'back_price_2', 'back_price_3', 'back_size_1', 'back_size_2', 'back_size_3',\n",
    "    'lay_price_1', 'lay_price_2', 'lay_price_3', 'lay_size_1', 'lay_size_2', 'lay_size_3'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_deets_cols = ['market_id', 'market_time', 'minutes_to_event', 'venue', 'event_name', 'race_type', 'market_name',\n",
    "                         'number_of_winners', 'number_of_runners', 'number_of_active_runners', 'version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_order_result(order_result):\n",
    "    instruction_report = order_result.get('instructionReports', [{}])[0]\n",
    "    instruction = instruction_report.get('instruction', {})\n",
    "    limit_order = instruction.get('limitOrder', {})\n",
    "    \n",
    "    return [\n",
    "        order_result.get('status', None),\n",
    "        order_result.get('marketId', None),\n",
    "        instruction.get('selectionId', None),\n",
    "        instruction.get('handicap', None),\n",
    "        limit_order.get('size', None),\n",
    "        limit_order.get('price', None),\n",
    "        limit_order.get('timeInForce', None),\n",
    "        limit_order.get('minFillSize', None),\n",
    "        instruction.get('orderType', None),\n",
    "        instruction.get('side', None),\n",
    "        instruction_report.get('errorCode', None),\n",
    "        instruction_report.get('betId', None),\n",
    "        instruction_report.get('placedDate', None),\n",
    "        instruction_report.get('averagePriceMatched', None),\n",
    "        instruction_report.get('sizeMatched', None),\n",
    "        instruction_report.get('orderStatus', None)\n",
    "    ]\n",
    "    \n",
    "order_cols = ['status', 'market_id', 'selection_id', 'handicap', 'size', 'price', 'time_in_force', 'min_fill_size',\n",
    "              'order_type', 'side', 'error_code', 'bet_id', 'placed_date', 'average_price_matched', 'size_matched', 'order_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_cols_to_db = ['runner_id', 'runner_name', 'status', 'market_id', 'market_type',\n",
    "       'market_id_win', 'market_id_place', 'api_call_time_utc', 'handicap',\n",
    "       'ltp', 'total_matched', 'back_price_1', 'back_price_2', 'back_price_3',\n",
    "       'back_size_1', 'back_size_2', 'back_size_3', 'lay_price_1',\n",
    "       'lay_price_2', 'lay_price_3', 'lay_size_1', 'lay_size_2', 'lay_size_3',\n",
    "       'odds_horse_win', 'odds_1_win', 'odds_2_win', 'odds_3_win',\n",
    "       'odds_4_win', 'odds_5_win', 'odds_6_win', 'odds_7_win', 'odds_8_win',\n",
    "       'odds_9_win', 'odds_10_win', 'odds_11_win', 'odds_12_win',\n",
    "       'odds_13_win', 'odds_14_win', 'odds_15_win', 'odds_16_win',\n",
    "       'odds_17_win', 'odds_18_win', 'odds_19_win', 'odds_20_win',\n",
    "       'odds_21_win', 'odds_22_win', 'market_time', 'minutes_to_event', 'venue', 'event_name',\n",
    "       'race_type', 'market_name', 'number_of_winners',\n",
    "       'number_of_runners_orig', 'number_of_runners', 'version', 'p_sum',\n",
    "       'minutes_to_event_rounded', 'preds', 'pred_odds', 'back', 'lay']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop to retrieve data, predict outcomes and place bets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 08:03:10.000532 UTC\n",
      "Parsed 85 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 21.949 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 08:33:31.138892 UTC\n",
      "Parsed 85 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 18.927 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 09:03:50.395346 UTC\n",
      "Parsed 85 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 19.401 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 09:34:09.794874 UTC\n",
      "Parsed 85 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 19.225 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 10:04:29.037637 UTC\n",
      "Parsed 85 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 18.899 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 10:34:48.012713 UTC\n",
      "Parsed 85 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 1 lay bets\n",
      "Bets placed!\n",
      "Data sent to DB\n",
      "Total time taken: 20.491 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 11:05:08.574571 UTC\n",
      "Parsed 86 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 1 lay bets\n",
      "Bets placed!\n",
      "Data sent to DB\n",
      "Total time taken: 18.902 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 11:35:27.606541 UTC\n",
      "Parsed 89 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 18.809 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 12:05:46.448699 UTC\n",
      "Parsed 90 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 18.701 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 12:36:05.318886 UTC\n",
      "Parsed 92 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 19.094 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 13:06:24.438452 UTC\n",
      "Parsed 92 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 19.067 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 13:36:43.699087 UTC\n",
      "Parsed 92 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 19.041 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 14:07:02.839827 UTC\n",
      "Parsed 89 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 1 back bets and 0 lay bets\n",
      "Bets placed!\n",
      "Data sent to DB\n",
      "Total time taken: 19.709 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 14:37:22.674447 UTC\n",
      "Parsed 88 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 1 lay bets\n",
      "Bets placed!\n",
      "Data sent to DB\n",
      "Total time taken: 18.807 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 15:07:41.474538 UTC\n",
      "Parsed 86 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 17.767 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 15:37:59.312515 UTC\n",
      "Parsed 84 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 17.842 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 16:08:17.274969 UTC\n",
      "Parsed 86 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 17.846 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 16:38:35.253635 UTC\n",
      "Parsed 81 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 17.027 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 17:08:52.334030 UTC\n",
      "Parsed 77 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 15.916 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 17:39:08.342450 UTC\n",
      "Parsed 98 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 20.466 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 18:09:28.926885 UTC\n",
      "Parsed 98 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 20.325 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 18:39:49.302930 UTC\n",
      "Parsed 101 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 21.001 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 19:10:10.387709 UTC\n",
      "Parsed 105 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 23.733 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 19:40:34.375159 UTC\n",
      "Parsed 101 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 24.437 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 20:10:58.819957 UTC\n",
      "Parsed 99 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 22.287 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 20:41:21.159961 UTC\n",
      "Parsed 99 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 20.863 seconds\n",
      "\n",
      "Logged in!\n",
      "Markets retrieved at 2021-05-27 21:11:42.125604 UTC\n",
      "Parsed 99 markets\n",
      "Odds retrieved\n",
      "Prediction data created\n",
      "Predictions done\n",
      "Found 0 back bets and 0 lay bets\n",
      "Data sent to DB\n",
      "Total time taken: 20.623 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-afa387b494da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Total time taken: {round(end_time - start_time, 3)} seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    \n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # GET EXISTING BETS FROM DB\n",
    "    connect_string = 'mysql+pymysql://root:'+dbpw+'@localhost/betfair'\n",
    "    sql_engine = sqlalchemy.create_engine(connect_string)\n",
    "    existing_bets = pd.read_sql('''\n",
    "                            SELECT DISTINCT selection_id as runner_id, market_id, side as existing_side, 1 AS existing_bet \n",
    "                            FROM order_results_live\n",
    "                            WHERE order_status = 'EXECUTION_COMPLETE'\n",
    "                            AND CAST(left(placed_date,10) AS DATETIME) >= curdate()\n",
    "                          ''',\n",
    "                          con=sql_engine)\n",
    "    existing_back_bets = existing_bets[existing_bets['existing_side']=='BACK']\n",
    "    existing_lay_bets = existing_bets[existing_bets['existing_side']=='LAY']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # LOGIN\n",
    "    try:\n",
    "        \n",
    "        login = requests.post('https://identitysso-cert.betfair.com/api/certlogin',\n",
    "                              cert=('/etc/ssl/client-2048.crt', '/etc/ssl/client-2048.key'),\n",
    "                              headers=header, data=auth)\n",
    "\n",
    "        login_success = login.json()['loginStatus']\n",
    "        logging.info('Login '+str(login_success))\n",
    "        ssoid = login.json()['sessionToken']\n",
    "        print('\\nLogged in!')\n",
    "\n",
    "    except Exception as error:\n",
    "        \n",
    "        login_status_code = login.status_code\n",
    "        logging.error('Login error '+str(login_status_code))\n",
    "        print('\\nLogin error, trying again in 1 minute')\n",
    "        \n",
    "        time.sleep(60)\n",
    "        continue\n",
    "\n",
    "    \n",
    "    headers = {'X-Application': application, 'X-Authentication': ssoid, 'content-type': 'application/json'}\n",
    "    \n",
    "    \n",
    "    \n",
    "    # GET MARKETS\n",
    "    try:\n",
    "        \n",
    "        event_id = '[\"7\"]'\n",
    "        countries = '[\"GB\", \"IE\"]'\n",
    "        market_types = '[\"WIN\", \"PLACE\"]'\n",
    "        market_start_time = (datetime.datetime.now() + datetime.timedelta(hours=-1)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        market_end_time = (datetime.datetime.now() + datetime.timedelta(hours=24)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        max_results = str(1000)\n",
    "        sort_type = 'FIRST_TO_START'\n",
    "        metadata = '[\"EVENT_TYPE\", \"COMPETITION\", \"EVENT\", \"MARKET_START_TIME\", \"MARKET_DESCRIPTION\", \"RUNNER_DESCRIPTION\"]' #, \"RUNNER_METADATA\"]'\n",
    "        inplay = 'false'\n",
    "\n",
    "        user_req='{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/listMarketCatalogue\",\\\n",
    "                   \"params\": {\"filter\":{\"eventTypeIds\":'+event_id+',\"marketTypeCodes\":'+market_types+',\\\n",
    "                   \"inPlayOnly\":'+inplay+', \"marketCountries\":'+countries+',  \\\n",
    "                   \"marketStartTime\":{\"from\":\"'+market_start_time+'\", \"to\":\"'+market_end_time+'\"}},\\\n",
    "                   \"sort\":\"'+sort_type+'\", \"maxResults\":\"'+max_results+'\", \"marketProjection\":'+metadata+'}, \"id\": 1}'\n",
    "\n",
    "        request = requests.post(bet_url, data=user_req.encode('utf-8'), headers=headers)\n",
    "        market_catalogue = request.json()['result']\n",
    "        logging.info('Markets retrieved ')\n",
    "        \n",
    "        market_info_time_utc = datetime.datetime.utcnow()\n",
    "        print('Markets retrieved at '+str(market_info_time_utc)+' UTC')\n",
    "        \n",
    "    except Exception as error:\n",
    "        \n",
    "        request_status_code = request.status_code\n",
    "        logging.error('Error getting markets, status code: '+str(request_status_code))\n",
    "        \n",
    "        time.sleep(60)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    # PARSE MARKET DETAILS\n",
    "    try:\n",
    "        market_definitions = []\n",
    "        runners = []\n",
    "        for m in market_catalogue:\n",
    "            market_definitions.append(parse_market_details(m))\n",
    "            runners += parse_runners(m)\n",
    "\n",
    "        market_definitions_df = pd.DataFrame(market_definitions, columns=md_cols)\n",
    "        market_definitions_df['api_call_time_utc'] = market_info_time_utc\n",
    "        runners_df = pd.DataFrame(runners, columns=r_cols)\n",
    "        runners_df['api_call_time_utc'] = market_info_time_utc\n",
    "        \n",
    "        # add time to event in order to select appropriate model\n",
    "        market_definitions_df['minutes_to_event'] = (\n",
    "            pd.to_datetime(market_definitions_df['market_time']) - pd.to_datetime(market_definitions_df['api_call_time_utc'], utc=True)).dt.seconds/60\n",
    "        \n",
    "        logging.info(f'Parsed {len(market_definitions_df)} markets')\n",
    "        print(f'Parsed {len(market_definitions_df)} markets')\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        logging.error('Error parsing markets')\n",
    "        \n",
    "        time.sleep(60)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    # GET ODDS\n",
    "    try:\n",
    "        markets = list(market_definitions_df['market_id'].unique())\n",
    "        market_books = []\n",
    "        for m in markets:\n",
    "\n",
    "            priceProjection = '[\"EX_BEST_OFFERS\"]'\n",
    "            prices_req = '{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/listMarketBook\",\\\n",
    "                            \"params\": {\"marketIds\": [\"' + m + '\"],\"priceProjection\":{\"priceData\":[\"EX_BEST_OFFERS\"]}}, \"id\": 1}'\n",
    "\n",
    "            request = requests.post(bet_url, data=prices_req.encode('utf-8'), headers=headers)\n",
    "            prices_result = request.json()\n",
    "\n",
    "            market_books.append(prices_result['result'][0])\n",
    "            \n",
    "        market_books_lists = []\n",
    "        market_odds_lists = []\n",
    "        for m in market_books:\n",
    "            market_books_lists.append(parse_market_book(m))\n",
    "            market_odds_lists += parse_market_odds(m)\n",
    "        \n",
    "        market_books_df = pd.DataFrame(market_books_lists, columns=mb_cols)\n",
    "        market_odds_df = pd.DataFrame(market_odds_lists, columns=mb_odds_cols)\n",
    "        \n",
    "        logging.info('Odds retrieved')\n",
    "        print('Odds retrieved')\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        logging.error('Error getting and parsing odds')\n",
    "        \n",
    "        time.sleep(60)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    # RESHAPE TO PREDICTION DATA\n",
    "    \n",
    "    # combine market info\n",
    "    md_len_check = len(market_definitions_df)\n",
    "    mb_len_check = len(market_books_df)\n",
    "\n",
    "    market_details_combined = market_definitions_df[market_definition_columns].merge(market_books_df[market_book_columns], how='left', on='market_id')\n",
    "\n",
    "    if md_len_check!=len(market_details_combined):\n",
    "        raise StopIteration('Duplicate markets!')\n",
    "\n",
    "    if mb_len_check!=len(market_details_combined):\n",
    "        raise StopIteration('Potentially missing some market details!')\n",
    "    \n",
    "    # combine runners and odds data\n",
    "    runner_len_check = len(runners_df)\n",
    "    odds_len_check = len(market_odds_df)\n",
    "\n",
    "    runners_and_odds = runners_df[runner_cols].merge(market_odds_df[market_odds_cols], how='left', on=['runner_id', 'market_id'])\n",
    "\n",
    "    if runner_len_check!=len(runners_and_odds):\n",
    "        raise StopIteration('Duplicate runners!')\n",
    "\n",
    "    if odds_len_check!=len(runners_and_odds):\n",
    "        raise StopIteration('Potentially missing runner or odds details!')\n",
    "    \n",
    "    # pair up win and place markets\n",
    "    place_market_details = market_details_combined[market_details_combined['market_type']=='PLACE']\n",
    "    win_market_details = market_details_combined[market_details_combined['market_type']=='WIN']\n",
    "\n",
    "    win_place_map = win_market_details[['event_id', 'market_time', 'market_id']].rename(columns={'market_id': 'market_id_win'}).merge(\n",
    "        place_market_details[['event_id', 'market_time', 'market_id']].rename(columns={'market_id': 'market_id_place'}),\n",
    "        how='left', on=['event_id', 'market_time'])\n",
    "\n",
    "    runners_and_odds = runners_and_odds.merge(market_details_combined[['market_id', 'market_type']], how='left', on='market_id')\n",
    "    \n",
    "    # add win odds to all runners data for ordering\n",
    "    runners_and_odds = runners_and_odds.merge(\n",
    "        win_place_map[['market_id_win', 'market_id_place']].rename(columns={'market_id_place': 'market_id'}), how='left', on='market_id')\n",
    "    runners_and_odds = runners_and_odds.merge(\n",
    "        win_place_map[['market_id_win', 'market_id_place']].rename(columns={'market_id_win': 'market_id'}), how='left', on='market_id')\n",
    "\n",
    "    runners_and_odds.loc[runners_and_odds['market_type']=='WIN', 'market_id_win'] = (\n",
    "        runners_and_odds.loc[runners_and_odds['market_type']=='WIN', 'market_id'])\n",
    "    runners_and_odds.loc[runners_and_odds['market_type']=='PLACE', 'market_id_place'] = (\n",
    "        runners_and_odds.loc[runners_and_odds['market_type']=='PLACE', 'market_id'])\n",
    "    \n",
    "    # merge runners and odds\n",
    "    r_and_o_len_check = len(runners_and_odds)\n",
    "    runners_and_odds = runners_and_odds.merge(\n",
    "        runners_and_odds[['runner_id', 'market_id', 'back_price_1']].rename(columns={'market_id': 'market_id_win', 'back_price_1': 'win_odds_1'}),\n",
    "        how='left', on=['runner_id', 'market_id_win'])\n",
    "\n",
    "    if r_and_o_len_check!=len(runners_and_odds):\n",
    "        raise StopIteration('Merge problems!')\n",
    "        \n",
    "    # sort and iteratively add runners\n",
    "    runners_and_odds = runners_and_odds.sort_values('win_odds_1')\n",
    "    runners_and_odds['odds_order'] = runners_and_odds.groupby('market_id').cumcount()\n",
    "    \n",
    "    runners_and_odds_piv = runners_and_odds.pivot_table(\n",
    "        values='win_odds_1',\n",
    "        index='market_id',\n",
    "        columns='odds_order',\n",
    "        aggfunc='mean',\n",
    "        fill_value=None\n",
    "    )\n",
    "    runners_and_odds_piv.columns = ['odds_'+str(c)+'_win' for c in runners_and_odds_piv.columns]\n",
    "    odds_cols = list(runners_and_odds_piv.columns)\n",
    "    max_runners = max(market_details_combined['number_of_active_runners'])\n",
    "    #odds_cols = ['odds_'+str(r)+'_win' for r in range(max_runners)]\n",
    "    prediction_data_list = []\n",
    "    for i in range(max_runners):\n",
    "        prediction_tmp = runners_and_odds[runners_and_odds['odds_order']==i]\n",
    "        prediction_tmp = prediction_tmp.merge(runners_and_odds_piv, how='left', on='market_id')\n",
    "        odds_cols_tmp = odds_cols.copy()\n",
    "        odds_cols_tmp.remove('odds_'+str(i)+'_win')\n",
    "\n",
    "        prediction_tmp = prediction_tmp.rename(columns={'odds_'+str(i)+'_win': 'odds_horse_win'})\n",
    "        prediction_data_cols = ['runner_id', 'runner_name', 'status', 'market_id', 'market_type', 'market_id_win', 'market_id_place', 'api_call_time_utc',\n",
    "                                'handicap', 'ltp', 'total_matched', 'back_price_1', 'back_price_2', 'back_price_3', 'back_size_1', 'back_size_2', 'back_size_3',\n",
    "                                'lay_price_1', 'lay_price_2', 'lay_price_3', 'lay_size_1', 'lay_size_2', 'lay_size_3',\n",
    "                                'odds_horse_win']\n",
    "        prediction_tmp = prediction_tmp[prediction_data_cols + odds_cols_tmp]\n",
    "        prediction_tmp.columns = prediction_data_cols + odds_cols[1:] # renaming odds names to have consecutive numbers\n",
    "        prediction_data_list.append(prediction_tmp)\n",
    "        \n",
    "    prediction_data_df = pd.concat(prediction_data_list, axis=0)\n",
    "    \n",
    "    # Add some market details\n",
    "    prediction_data_df = prediction_data_df.merge(market_details_combined[market_deets_cols], how='left', on='market_id')\n",
    "    prediction_data_df = prediction_data_df.rename(columns={'number_of_runners': 'number_of_runners_orig', 'number_of_active_runners': 'number_of_runners'})\n",
    "    \n",
    "    print('Prediction data created')\n",
    "    logging.info('Prediction data created')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # CHECK AND SUBSET DATA\n",
    "    runners_and_odds['p_back_price_1'] = 1/runners_and_odds['back_price_1']\n",
    "    prob_sums = runners_and_odds.groupby('market_id')['p_back_price_1'].sum().reset_index().rename(columns={'p_back_price_1': 'p_sum'})\n",
    "    prediction_data_df = prediction_data_df.merge(prob_sums.rename(columns={'market_id': 'market_id_win'}), how='left', on='market_id_win')\n",
    "    \n",
    "    number_winners = 3\n",
    "    runners_min = 8\n",
    "    runners_max = 15\n",
    "    win_p_sum_min = 0.95\n",
    "    win_p_sum_max = 1.5\n",
    "\n",
    "    prediction_data_df = prediction_data_df[\n",
    "        (prediction_data_df['market_type']=='PLACE') &\n",
    "        (prediction_data_df['number_of_winners']==number_winners) &\n",
    "        (prediction_data_df['number_of_runners'].between(runners_min, runners_max)) &\n",
    "        (prediction_data_df['p_sum'].between(win_p_sum_min, win_p_sum_max))]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # MAKE NULLS TO DEFAULTS WHERE NO RUNNERS\n",
    "    features = ['number_of_runners', 'odds_horse_win'] + ['odds_'+str(i+1)+'_win' for i in range(runners_max-1)]\n",
    "    default_odds = 99999\n",
    "    for f in features:\n",
    "        if f in prediction_data_df.columns:\n",
    "            prediction_data_df[f] = prediction_data_df[f].fillna(default_odds)\n",
    "        else:\n",
    "            prediction_data_df[f] = default_odds\n",
    "    \n",
    "    \n",
    "    \n",
    "    # CREATE SEPARATE DATA FOR EACH MODEL AND DO PREDICTIONS\n",
    "    prediction_data_df['minutes_to_event_rounded'] = 30*((prediction_data_df['minutes_to_event']/30).astype(int))\n",
    "\n",
    "    prediction_data_60 = prediction_data_df[prediction_data_df['minutes_to_event_rounded']==60]\n",
    "    d60 = xgb.DMatrix(prediction_data_60[features])\n",
    "    prediction_data_60['preds'] = betfair_places_model_60.predict(d60)\n",
    "    prediction_data_60['pred_odds'] = 1/prediction_data_60['preds']\n",
    "\n",
    "    prediction_data_120 = prediction_data_df[prediction_data_df['minutes_to_event_rounded']==120]\n",
    "    d120 = xgb.DMatrix(prediction_data_120[features])\n",
    "    prediction_data_120['preds'] = betfair_places_model_120.predict(d120)\n",
    "    prediction_data_120['pred_odds'] = 1/prediction_data_120['preds']\n",
    "\n",
    "    prediction_data_180 = prediction_data_df[prediction_data_df['minutes_to_event_rounded']==180]\n",
    "    d180 = xgb.DMatrix(prediction_data_180[features])\n",
    "    prediction_data_180['preds'] = betfair_places_model_180.predict(d180)\n",
    "    prediction_data_180['pred_odds'] = 1/prediction_data_180['preds']\n",
    "\n",
    "    prediction_data_240 = prediction_data_df[prediction_data_df['minutes_to_event_rounded']==240]\n",
    "    d240 = xgb.DMatrix(prediction_data_240[features])\n",
    "    prediction_data_240['preds'] = betfair_places_model_240.predict(d240)\n",
    "    prediction_data_240['pred_odds'] = 1/prediction_data_240['preds']\n",
    "\n",
    "    prediction_data_300 = prediction_data_df[prediction_data_df['minutes_to_event_rounded']==300]\n",
    "    d300 = xgb.DMatrix(prediction_data_300[features])\n",
    "    prediction_data_300['preds'] = betfair_places_model_300.predict(d300)\n",
    "    prediction_data_300['pred_odds'] = 1/prediction_data_300['preds']\n",
    "\n",
    "    output_data = pd.concat([prediction_data_60, prediction_data_120, prediction_data_180, prediction_data_240, prediction_data_300], axis=0)\n",
    "        \n",
    "    print('Predictions done')\n",
    "    logging.info('Predictions done')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ADD BETTING CONSTRAINTS\n",
    "    # back bets\n",
    "    odds_margin_mult = 1.1\n",
    "    min_odds = 1\n",
    "    max_odds = 2.5\n",
    "    min_time_to_event = 0\n",
    "    max_time_to_event = 240\n",
    "\n",
    "    if allow_subsequent_bets_on_same_runner:\n",
    "        back_mask = ((output_data['pred_odds']*odds_margin_mult<output_data['back_price_1'])\n",
    "                     & (output_data['back_price_1'].between(min_odds, max_odds))\n",
    "                     & (output_data['minutes_to_event_rounded']>=min_time_to_event)\n",
    "                     & (output_data['minutes_to_event_rounded']<=max_time_to_event)\n",
    "                    )\n",
    "    \n",
    "    else:\n",
    "        existing_bets_check = output_data.merge(existing_back_bets[['runner_id', 'market_id', 'existing_side', 'existing_bet']],\n",
    "                                                how='left', on=['runner_id', 'market_id'])\n",
    "        existing_bets_mask = (existing_bets_check['existing_bet']==1)        \n",
    "        back_mask = ((output_data['pred_odds']*odds_margin_mult<output_data['back_price_1'])\n",
    "                     & (output_data['back_price_1'].between(min_odds, max_odds))\n",
    "                     & (output_data['minutes_to_event_rounded']>=min_time_to_event)\n",
    "                     & (output_data['minutes_to_event_rounded']<=max_time_to_event)\n",
    "                     & ~(existing_bets_mask.values))\n",
    "        \n",
    "\n",
    "    output_data['back'] = 0\n",
    "    output_data.loc[back_mask, 'back'] = 1\n",
    "    back_bets = output_data[output_data['back']==1]\n",
    "    \n",
    "    # lay bets\n",
    "    lay_margin = 1.1\n",
    "    lay_odds_min = 0\n",
    "    lay_odds_max = 2.5\n",
    "    lay_min_time_to_event = 0\n",
    "    lay_max_time_to_event = 240\n",
    "\n",
    "    if allow_subsequent_bets_on_same_runner:\n",
    "        lay_mask = ((output_data['pred_odds'] > output_data['lay_price_1']*lay_margin)\n",
    "                    & (output_data['lay_price_1'].between(lay_odds_min, lay_odds_max))\n",
    "                    & (output_data['minutes_to_event_rounded']>=lay_min_time_to_event)\n",
    "                    & (output_data['minutes_to_event_rounded']<=lay_max_time_to_event)\n",
    "                   )\n",
    "    \n",
    "    else:\n",
    "        existing_bets_check = output_data.merge(existing_lay_bets[['runner_id', 'market_id', 'existing_side', 'existing_bet']],\n",
    "                                                how='left', on=['runner_id', 'market_id'])\n",
    "        existing_bets_mask = (existing_bets_check['existing_bet']==1)        \n",
    "        lay_mask = ((output_data['pred_odds'] > output_data['lay_price_1']*lay_margin)\n",
    "                    & (output_data['lay_price_1'].between(lay_odds_min, lay_odds_max))\n",
    "                    & (output_data['minutes_to_event_rounded']>=lay_min_time_to_event)\n",
    "                    & (output_data['minutes_to_event_rounded']<=lay_max_time_to_event)\n",
    "                    & ~(existing_bets_mask.values))\n",
    "\n",
    "    output_data['lay'] = 0\n",
    "    output_data.loc[lay_mask, 'lay'] = 1\n",
    "    lay_bets = output_data[output_data['lay']==1]\n",
    "    \n",
    "    print(f'Found {len(back_bets)} back bets and {len(lay_bets)} lay bets')\n",
    "    logging.info(f'Found {len(back_bets)} back bets and {len(lay_bets)} lay bets')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # PLACE BETS\n",
    "    order_results = []\n",
    "    order_fails = []\n",
    "    \n",
    "    max_bet = 2\n",
    "\n",
    "    # back bets\n",
    "    for i in back_bets.index:\n",
    "        market_id = str(back_bets.at[i, 'market_id'])\n",
    "        selection_id = str(back_bets.at[i, 'runner_id'])\n",
    "        available = back_bets.at[i, 'back_size_1']\n",
    "        bet_size = str(min(available, max_bet))\n",
    "        price = str(back_bets.at[i, 'back_price_1'])\n",
    "        min_fill_size = str(2)\n",
    "        market_version = str(back_bets.at[i, 'version'])\n",
    "\n",
    "        try:\n",
    "            order_request = '{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/placeOrders\",\\\n",
    "                        \"params\": {\"marketId\":\"' + market_id + '\",\"instructions\":[\\\n",
    "                        {\"selectionId\":\"' + selection_id + '\",\"handicap\":\"0\",\"side\":\"BACK\",\"orderType\":\"LIMIT\",\\\n",
    "                        \"limitOrder\":{\"size\":\"' + bet_size + '\",\"price\":\"' + price + '\",\"persistenceType\":\"LAPSE\",\\\n",
    "                        \"timeInForce\":\"FILL_OR_KILL\", \"minFillSize\":\"' + min_fill_size + '\"}}], \"marketVersion\":{\"version\":\"' + market_version + '\"}}, \"id\": 1}'\n",
    "            request = requests.post(bet_url, data=order_request.encode('utf-8'), headers=headers)\n",
    "            order_result = request.json()['result']\n",
    "            order_results.append(order_result)\n",
    "        except:\n",
    "            order_fails.append([market_id, selection_id, available, bet_size, price, min_fill_size, market_version])\n",
    "    \n",
    "    # lay bets\n",
    "    max_bet = 2\n",
    "\n",
    "    for i in lay_bets.index:\n",
    "        market_id = str(lay_bets.at[i, 'market_id'])\n",
    "        selection_id = str(lay_bets.at[i, 'runner_id'])\n",
    "        available = lay_bets.at[i, 'lay_size_1']\n",
    "        bet_size = str(min(available, max_bet))\n",
    "        price = str(lay_bets.at[i, 'lay_price_1'])\n",
    "        min_fill_size = str(2)\n",
    "        market_version = str(lay_bets.at[i, 'version'])\n",
    "\n",
    "        try:\n",
    "            order_request = '{\"jsonrpc\": \"2.0\", \"method\": \"SportsAPING/v1.0/placeOrders\",\\\n",
    "                        \"params\": {\"marketId\":\"' + market_id + '\",\"instructions\":[\\\n",
    "                        {\"selectionId\":\"' + selection_id + '\",\"handicap\":\"0\",\"side\":\"LAY\",\"orderType\":\"LIMIT\",\\\n",
    "                        \"limitOrder\":{\"size\":\"' + bet_size + '\",\"price\":\"' + price + '\",\"persistenceType\":\"LAPSE\",\\\n",
    "                        \"timeInForce\":\"FILL_OR_KILL\", \"minFillSize\":\"' + min_fill_size + '\"}}], \"marketVersion\":{\"version\":\"' + market_version + '\"}}, \"id\": 1}'\n",
    "            request = requests.post(bet_url, data=order_request.encode('utf-8'), headers=headers)\n",
    "            order_result = request.json()['result']\n",
    "            order_results.append(order_result)\n",
    "        except:\n",
    "            order_fails.append([market_id, selection_id, available, bet_size, price, min_fill_size, market_version])\n",
    "    \n",
    "    if len(back_bets) + len(lay_bets) > 0:\n",
    "        # might be nice to do more here, like count number of executed and number of failed bets\n",
    "        print('Bets placed!')\n",
    "        logging.info('Bets placed!')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # GET RESULTS AND SEND DATA TO DB\n",
    "    order_results_df = []\n",
    "    for o in order_results:\n",
    "        order_results_df.append(parse_order_result(o))\n",
    "    order_results_df = pd.DataFrame(order_results_df, columns=order_cols)\n",
    "\n",
    "    order_fails_df = pd.DataFrame(order_fails, columns=['market_id', 'selection_id', 'available', 'bet_size', 'price', 'min_fill_size', 'market_version'])\n",
    "    \n",
    "    connect_string = 'mysql+pymysql://root:'+dbpw+'@localhost/betfair'\n",
    "    sql_engine = sqlalchemy.create_engine(connect_string)\n",
    "    \n",
    "    market_details_combined.to_sql(name='market_details_combined_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "    runners_and_odds.to_sql(name='runners_and_odds_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "    \n",
    "    prediction_cols_to_db_tmp = [p for p in prediction_cols_to_db if p in output_data.columns]\n",
    "    output_data[prediction_cols_to_db_tmp].to_sql(name='predictions_output_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "    order_results_df.to_sql(name='order_results_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "    order_fails_df.to_sql(name='order_fails_live', con=sql_engine, schema='betfair', if_exists='append', index=False)\n",
    "    \n",
    "    print('Data sent to DB')\n",
    "    logging.info('Data sent to DB')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # SLEEP AND REPEAT\n",
    "    end_time = time.time()\n",
    "    print(f'Total time taken: {round(end_time - start_time, 3)} seconds')\n",
    "    time.sleep(30*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note some bets being placed when back-lay margin is large. Make sure to analyse this once have sufficient data (could even do analysis on all of the data that is stored, not just those which have been bet on).\n",
    "\n",
    "## ALSO NOTICED SOME STARK DIFFERENCES IN PREDS WHEN ODDS HAVEN'T CHANGED BY MUCH SO NEED TO INVESTIGATE THERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
